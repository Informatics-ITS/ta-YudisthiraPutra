{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_Q04k73hQBe"
      },
      "source": [
        "---\n",
        "### **IMPORT LIBRARIES AND DEPENDANCIES**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LU26fr7IHEhD",
        "outputId": "aa952c27-29fb-403f-bb1b-1ac31757434a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-18 11:53:13--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.227.219.33, 13.227.219.59, 13.227.219.10, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.227.219.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1227018698 (1.1G) [binary/octet-stream]\n",
            "Saving to: ‘cc.id.300.vec.gz’\n",
            "\n",
            "cc.id.300.vec.gz    100%[===================>]   1.14G   118MB/s    in 11s     \n",
            "\n",
            "2025-06-18 11:53:25 (103 MB/s) - ‘cc.id.300.vec.gz’ saved [1227018698/1227018698]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.vec.gz\n",
        "!gunzip cc.id.300.vec.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-59dsvEnO57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        },
        "outputId": "58538976-8586-4681-ea69-5666a2f9ba4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "\u001b[33mWARNING: Skipping gensim as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting numpy==1.25.2\n",
            "  Downloading numpy-1.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Downloading numpy-1.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "blosc2 3.3.4 requires numpy>=1.26, but you have numpy 1.25.2 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.25.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.25.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.25.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "90adbffd60274a4b86cbe78dad980514"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.25.2)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy, gensim\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y numpy gensim\n",
        "!pip install numpy==1.25.2  # Compatible with TensorFlow and Gensim\n",
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zn7LNII-azzU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9afc3ea-2429-485d-ff0f-3ef033104395"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Collecting stanza\n",
            "  Downloading stanza-1.10.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Collecting sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.25.2)\n",
            "Collecting gensim\n",
            "  Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Collecting emoji (from stanza)\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.11/dist-packages (from stanza) (5.29.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from stanza) (2.32.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from stanza) (3.5)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from stanza) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (4.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.3.0->stanza) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.3.0->stanza) (3.0.2)\n",
            "Downloading stanza-1.10.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp311-cp311-linux_x86_64.whl size=4313510 sha256=6d992a758af39f4427aec09f64ab4b5b31a160247b8a28f89a426642ca9dcd8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/35/5057db0249224e9ab55a513fa6b79451473ceb7713017823c3\n",
            "Successfully built fasttext\n",
            "Installing collected packages: sastrawi, pybind11, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, emoji, nvidia-cusparse-cu12, nvidia-cudnn-cu12, gensim, fasttext, nvidia-cusolver-cu12, stanza\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed emoji-2.14.1 fasttext-0.9.3 gensim-4.3.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pybind11-2.13.6 sastrawi-1.0.1 stanza-1.10.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas nltk matplotlib stanza scikit-learn sastrawi fasttext numpy gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mR5hmdFnI8hO"
      },
      "outputs": [],
      "source": [
        "# Load FastText embeddings with gensim\n",
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "fasttext_model = KeyedVectors.load_word2vec_format('cc.id.300.vec', binary=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oWSe_3ThQBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90cef3bd-e284-45e8-fb55-5e41bddddc01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import re\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import stanza\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from nltk.corpus import wordnet as wn, stopwords\n",
        "import ast\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "en0CKazz1DoW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b883b44-f33c-4721-8f74-e217c7bc698e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9abKm9hF3Vs"
      },
      "source": [
        "---\n",
        "### **LOAD DATA**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "DYawcjHYF0qp",
        "outputId": "144360df-3b6f-4025-9689-6841cbbd0e62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      story_id    person                                  aliases  \\\n",
              "0           28  Tokoh-11                                ['ambun']   \n",
              "1           16   Tokoh-4      ['kepala', 'kepala tador', 'tador']   \n",
              "2           16   Tokoh-1  ['ibu tador', 'ibunya', 'ibumu', 'ibu']   \n",
              "3           10   Tokoh-5                       ['raja margolang']   \n",
              "4           10  Tokoh-11                       ['sipakpak kunal']   \n",
              "...        ...       ...                                      ...   \n",
              "1845        13   Tokoh-9                  ['orang anak', 'orang']   \n",
              "1846        25   Tokoh-1                        ['ibunya', 'ibu']   \n",
              "1847        13   Tokoh-8  ['datu', 'datu kandibata', 'kandibata']   \n",
              "1848       109  Tokoh-10                                ['orang']   \n",
              "1849        23  Tokoh-12                                  ['nak']   \n",
              "\n",
              "                                      subject_sentences  is_dialogue  \\\n",
              "0                               Ambun kembali bertanya.            0   \n",
              "1     Tador tidak menyangka kalau dia ditinggal di r...            0   \n",
              "2     Akan tetapi, kalau mengharapkan bantuan sang i...            0   \n",
              "3             Raja Margolang menyetujui saran tersebut.            0   \n",
              "4                              Namanya Sipakpak Kunal.\"            1   \n",
              "...                                                 ...          ...   \n",
              "1845  Berapa orang yang kau kehendaki membawa tapak ...            0   \n",
              "1846  Sementara itu, sang ibu yang tidak tahan lagi ...            0   \n",
              "1847  Datu Kandibata dan isterinya terus menghemoask...            0   \n",
              "1848  Rumah mereka seperti kebanyakan rumah orang la...            0   \n",
              "1849                           \"Ibu tidak sengaja, Nak.            1   \n",
              "\n",
              "      is_subject  count_lexicon        label  \n",
              "0              1              1  protagonist  \n",
              "1              1              2  protagonist  \n",
              "2              0              1   antagonist  \n",
              "3              0              1       others  \n",
              "4              0              0   antagonist  \n",
              "...          ...            ...          ...  \n",
              "1845           1              1       others  \n",
              "1846           1              2  protagonist  \n",
              "1847           1              1   antagonist  \n",
              "1848           0              0       others  \n",
              "1849           0              0   antagonist  \n",
              "\n",
              "[1850 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fead671b-56d0-49bf-a1ef-0b8a022fb372\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>story_id</th>\n",
              "      <th>person</th>\n",
              "      <th>aliases</th>\n",
              "      <th>subject_sentences</th>\n",
              "      <th>is_dialogue</th>\n",
              "      <th>is_subject</th>\n",
              "      <th>count_lexicon</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28</td>\n",
              "      <td>Tokoh-11</td>\n",
              "      <td>['ambun']</td>\n",
              "      <td>Ambun kembali bertanya.</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>protagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16</td>\n",
              "      <td>Tokoh-4</td>\n",
              "      <td>['kepala', 'kepala tador', 'tador']</td>\n",
              "      <td>Tador tidak menyangka kalau dia ditinggal di r...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>protagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16</td>\n",
              "      <td>Tokoh-1</td>\n",
              "      <td>['ibu tador', 'ibunya', 'ibumu', 'ibu']</td>\n",
              "      <td>Akan tetapi, kalau mengharapkan bantuan sang i...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>Tokoh-5</td>\n",
              "      <td>['raja margolang']</td>\n",
              "      <td>Raja Margolang menyetujui saran tersebut.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>Tokoh-11</td>\n",
              "      <td>['sipakpak kunal']</td>\n",
              "      <td>Namanya Sipakpak Kunal.\"</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1845</th>\n",
              "      <td>13</td>\n",
              "      <td>Tokoh-9</td>\n",
              "      <td>['orang anak', 'orang']</td>\n",
              "      <td>Berapa orang yang kau kehendaki membawa tapak ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1846</th>\n",
              "      <td>25</td>\n",
              "      <td>Tokoh-1</td>\n",
              "      <td>['ibunya', 'ibu']</td>\n",
              "      <td>Sementara itu, sang ibu yang tidak tahan lagi ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>protagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1847</th>\n",
              "      <td>13</td>\n",
              "      <td>Tokoh-8</td>\n",
              "      <td>['datu', 'datu kandibata', 'kandibata']</td>\n",
              "      <td>Datu Kandibata dan isterinya terus menghemoask...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1848</th>\n",
              "      <td>109</td>\n",
              "      <td>Tokoh-10</td>\n",
              "      <td>['orang']</td>\n",
              "      <td>Rumah mereka seperti kebanyakan rumah orang la...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1849</th>\n",
              "      <td>23</td>\n",
              "      <td>Tokoh-12</td>\n",
              "      <td>['nak']</td>\n",
              "      <td>\"Ibu tidak sengaja, Nak.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>antagonist</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1850 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fead671b-56d0-49bf-a1ef-0b8a022fb372')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fead671b-56d0-49bf-a1ef-0b8a022fb372 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fead671b-56d0-49bf-a1ef-0b8a022fb372');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-86dbbf29-8e51-4342-ab49-e3adeb1cd707\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86dbbf29-8e51-4342-ab49-e3adeb1cd707')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-86dbbf29-8e51-4342-ab49-e3adeb1cd707 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_7000c0a8-a709-4ab5-8541-3c45ea3d7a57\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7000c0a8-a709-4ab5-8541-3c45ea3d7a57 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1850,\n  \"fields\": [\n    {\n      \"column\": \"story_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40,\n        \"min\": 6,\n        \"max\": 114,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          28,\n          7,\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"person\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 33,\n        \"samples\": [\n          \"Tokoh-27\",\n          \"Tokoh-13\",\n          \"Tokoh-22\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aliases\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 207,\n        \"samples\": [\n          \"['raksasa']\",\n          \"['ramuan', 'nenek', 'ramuan nenek']\",\n          \"['anaknya', 'anakku', 'anak']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subject_sentences\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1850,\n        \"samples\": [\n          \"Si Jibau memahami maksudnya dan memakan sirih tersebut.\",\n          \"Demikianlah keluhan sang raja ketika mengetahui kelakuan anaknya itu.\",\n          \"Ayah, ibu, kakek, dan nenek seakan tidak mau bergantian menggendongnya.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_dialogue\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_subject\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count_lexicon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": -6,\n        \"max\": 13,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          6,\n          -6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"protagonist\",\n          \"antagonist\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/thesis_implementation_code/data_train_dl.csv\")\n",
        "df = df[['story_id', 'person', 'aliases', 'subject_sentences', \"is_dialogue\", \"is_subject\", \"count_lexicon\", 'label']]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QlYGeTLJQAV",
        "outputId": "9d8fba3a-0d2e-48cf-f365-3f066c819d27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1850 entries, 0 to 1849\n",
            "Data columns (total 8 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   story_id           1850 non-null   int64 \n",
            " 1   person             1850 non-null   object\n",
            " 2   aliases            1850 non-null   object\n",
            " 3   subject_sentences  1850 non-null   object\n",
            " 4   is_dialogue        1850 non-null   int64 \n",
            " 5   is_subject         1850 non-null   int64 \n",
            " 6   count_lexicon      1850 non-null   int64 \n",
            " 7   label              1850 non-null   object\n",
            "dtypes: int64(4), object(4)\n",
            "memory usage: 115.8+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sf7WE4PiJa4U"
      },
      "outputs": [],
      "source": [
        "train_df = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "S9TRFdJeJvXM",
        "outputId": "9a84f5fb-da55-4d59-b1cc-48b5f2108d3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "others         717\n",
              "protagonist    650\n",
              "antagonist     483\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>others</th>\n",
              "      <td>717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>protagonist</th>\n",
              "      <td>650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>antagonist</th>\n",
              "      <td>483</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "QE8CULNLwiGj",
        "outputId": "795c958e-7d97-4a32-91e9-9944ed0bcbbc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     story_id    person                                        aliases  \\\n",
              "0          28   Tokoh-6  ['nak', 'orang anak', 'orang', 'orang kakak']   \n",
              "1          13   Tokoh-9                        ['orang anak', 'orang']   \n",
              "2         111   Tokoh-4                  ['anaknya', 'anakku', 'anak']   \n",
              "3         105  Tokoh-18                                ['banta ahmad']   \n",
              "4         109   Tokoh-2        ['ayah siti sara', 'ayahnya', 'ayahmu']   \n",
              "..        ...       ...                                            ...   \n",
              "458        57   Tokoh-3                                     ['kepala']   \n",
              "459        23   Tokoh-4              ['anak gadis', 'anaknya', 'anak']   \n",
              "460        79   Tokoh-8                              ['chandrakirana']   \n",
              "461        15   Tokoh-9                                 ['sri pandan']   \n",
              "462       106  Tokoh-14                                       ['naga']   \n",
              "\n",
              "                                     subject_sentences  is_dialogue  \\\n",
              "0    Banyak orang di kampung itu mengira mereka sau...            0   \n",
              "1    Berapa orang pesuruh yang ku kehendaki akan ku...            0   \n",
              "2    Kemudian anak raja ini menyerahkan uang kepada...            0   \n",
              "3        Lalu Banta Ahmad dibawa pulang untuk diobati.            0   \n",
              "4    \"Pesan ibu padamu, anakku, agar nanti engkau m...            1   \n",
              "..                                                 ...          ...   \n",
              "458  Petani segera menuju ke rumah Kepala Desa untu...            0   \n",
              "459  Dia tinggal berdua dengan Siti, anak gadisnya ...            0   \n",
              "460  Ia ingat tugas Chandrakirana yang tiap hari me...            0   \n",
              "461  Di tengah perjalanan menuju lubuk, Sri Pandan ...            0   \n",
              "462  Sedang ia bermenung, muncullah seekor ikan bes...            0   \n",
              "\n",
              "     is_subject  count_lexicon        label  \n",
              "0             1              2       others  \n",
              "1             1              0       others  \n",
              "2             1              1  protagonist  \n",
              "3             0              0  protagonist  \n",
              "4             0             -2  protagonist  \n",
              "..          ...            ...          ...  \n",
              "458           0              0       others  \n",
              "459           0              2   antagonist  \n",
              "460           0              2  protagonist  \n",
              "461           0              0  protagonist  \n",
              "462           0              5       others  \n",
              "\n",
              "[463 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4799f5c7-25c2-49e0-bb3f-33abcd7bddd4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>story_id</th>\n",
              "      <th>person</th>\n",
              "      <th>aliases</th>\n",
              "      <th>subject_sentences</th>\n",
              "      <th>is_dialogue</th>\n",
              "      <th>is_subject</th>\n",
              "      <th>count_lexicon</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28</td>\n",
              "      <td>Tokoh-6</td>\n",
              "      <td>['nak', 'orang anak', 'orang', 'orang kakak']</td>\n",
              "      <td>Banyak orang di kampung itu mengira mereka sau...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13</td>\n",
              "      <td>Tokoh-9</td>\n",
              "      <td>['orang anak', 'orang']</td>\n",
              "      <td>Berapa orang pesuruh yang ku kehendaki akan ku...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>111</td>\n",
              "      <td>Tokoh-4</td>\n",
              "      <td>['anaknya', 'anakku', 'anak']</td>\n",
              "      <td>Kemudian anak raja ini menyerahkan uang kepada...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>protagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>105</td>\n",
              "      <td>Tokoh-18</td>\n",
              "      <td>['banta ahmad']</td>\n",
              "      <td>Lalu Banta Ahmad dibawa pulang untuk diobati.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>protagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>109</td>\n",
              "      <td>Tokoh-2</td>\n",
              "      <td>['ayah siti sara', 'ayahnya', 'ayahmu']</td>\n",
              "      <td>\"Pesan ibu padamu, anakku, agar nanti engkau m...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>protagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>57</td>\n",
              "      <td>Tokoh-3</td>\n",
              "      <td>['kepala']</td>\n",
              "      <td>Petani segera menuju ke rumah Kepala Desa untu...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>23</td>\n",
              "      <td>Tokoh-4</td>\n",
              "      <td>['anak gadis', 'anaknya', 'anak']</td>\n",
              "      <td>Dia tinggal berdua dengan Siti, anak gadisnya ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>79</td>\n",
              "      <td>Tokoh-8</td>\n",
              "      <td>['chandrakirana']</td>\n",
              "      <td>Ia ingat tugas Chandrakirana yang tiap hari me...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>protagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>15</td>\n",
              "      <td>Tokoh-9</td>\n",
              "      <td>['sri pandan']</td>\n",
              "      <td>Di tengah perjalanan menuju lubuk, Sri Pandan ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>protagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>106</td>\n",
              "      <td>Tokoh-14</td>\n",
              "      <td>['naga']</td>\n",
              "      <td>Sedang ia bermenung, muncullah seekor ikan bes...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>463 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4799f5c7-25c2-49e0-bb3f-33abcd7bddd4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4799f5c7-25c2-49e0-bb3f-33abcd7bddd4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4799f5c7-25c2-49e0-bb3f-33abcd7bddd4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a2c99114-aedf-433d-a741-5c4a38d15950\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a2c99114-aedf-433d-a741-5c4a38d15950')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a2c99114-aedf-433d-a741-5c4a38d15950 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_be65e3c3-45ef-4718-8ca3-77394d38b977\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_be65e3c3-45ef-4718-8ca3-77394d38b977 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 463,\n  \"fields\": [\n    {\n      \"column\": \"story_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40,\n        \"min\": 6,\n        \"max\": 114,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          28,\n          6,\n          79\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"person\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          \"Tokoh-17\",\n          \"Tokoh-7\",\n          \"Tokoh-6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aliases\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 136,\n        \"samples\": [\n          \"['temannya', 'teman']\",\n          \"['dusun tanjung siman', 'tanjung siman', 'dusun']\",\n          \"['bu', 'bu nenek', 'nenek', 'nek']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subject_sentences\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 463,\n        \"samples\": [\n          \"Selama di kampung, anak itu tidak mempunyai pekerjaan.\",\n          \"Siti Sara hanya menangis, air matanya bercucuran.\",\n          \"Namun, di sungai tempat Leniri terjun, ikan patin banyak ditemukan di sana.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_dialogue\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_subject\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count_lexicon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": -5,\n        \"max\": 5,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          -1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"others\",\n          \"protagonist\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "test_df = pd.read_csv(\"/content/drive/MyDrive/thesis_implementation_code/data_test_dl.csv\")\n",
        "test_df = test_df[['story_id', 'person', 'aliases', 'subject_sentences', \"is_dialogue\", \"is_subject\", \"count_lexicon\", 'label']]\n",
        "test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di_hj1EU4Alu"
      },
      "source": [
        "---\n",
        "### **FEATURE ENGINEERING**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kVlc2rt6wvh"
      },
      "source": [
        "#### **PREPROCESS TEXT FEATURE**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "Bb4ELRxq3lpa",
        "outputId": "06180871-f6d8-466a-9ff5-90adafe53242"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      story_id    person                                  aliases  \\\n",
              "0           28  Tokoh-11                                ['ambun']   \n",
              "1           16   Tokoh-4      ['kepala', 'kepala tador', 'tador']   \n",
              "2           16   Tokoh-1  ['ibu tador', 'ibunya', 'ibumu', 'ibu']   \n",
              "3           10   Tokoh-5                       ['raja margolang']   \n",
              "4           10  Tokoh-11                       ['sipakpak kunal']   \n",
              "...        ...       ...                                      ...   \n",
              "1845        13   Tokoh-9                  ['orang anak', 'orang']   \n",
              "1846        25   Tokoh-1                        ['ibunya', 'ibu']   \n",
              "1847        13   Tokoh-8  ['datu', 'datu kandibata', 'kandibata']   \n",
              "1848       109  Tokoh-10                                ['orang']   \n",
              "1849        23  Tokoh-12                                  ['nak']   \n",
              "\n",
              "                                      subject_sentences  is_dialogue  \\\n",
              "0                                ambun kembali bertanya            0   \n",
              "1     tador tidak menyangka kalau dia ditinggal di r...            0   \n",
              "2     akan tetapi kalau mengharapkan bantuan sang ib...            0   \n",
              "3              raja margolang menyetujui saran tersebut            0   \n",
              "4                                namanya sipakpak kunal            1   \n",
              "...                                                 ...          ...   \n",
              "1845  berapa orang yang kau kehendaki membawa tapak ...            0   \n",
              "1846  sementara itu sang ibu yang tidak tahan lagi m...            0   \n",
              "1847  datu kandibata dan isterinya terus menghemoask...            0   \n",
              "1848  rumah mereka seperti kebanyakan rumah orang la...            0   \n",
              "1849                              ibu tidak sengaja nak            1   \n",
              "\n",
              "      is_subject  count_lexicon        label  \n",
              "0              1              1  protagonist  \n",
              "1              1              2  protagonist  \n",
              "2              0              1   antagonist  \n",
              "3              0              1       others  \n",
              "4              0              0   antagonist  \n",
              "...          ...            ...          ...  \n",
              "1845           1              1       others  \n",
              "1846           1              2  protagonist  \n",
              "1847           1              1   antagonist  \n",
              "1848           0              0       others  \n",
              "1849           0              0   antagonist  \n",
              "\n",
              "[1850 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34d217f8-bef8-4d2b-9a3b-7d7ec0f3b427\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>story_id</th>\n",
              "      <th>person</th>\n",
              "      <th>aliases</th>\n",
              "      <th>subject_sentences</th>\n",
              "      <th>is_dialogue</th>\n",
              "      <th>is_subject</th>\n",
              "      <th>count_lexicon</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28</td>\n",
              "      <td>Tokoh-11</td>\n",
              "      <td>['ambun']</td>\n",
              "      <td>ambun kembali bertanya</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>protagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16</td>\n",
              "      <td>Tokoh-4</td>\n",
              "      <td>['kepala', 'kepala tador', 'tador']</td>\n",
              "      <td>tador tidak menyangka kalau dia ditinggal di r...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>protagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16</td>\n",
              "      <td>Tokoh-1</td>\n",
              "      <td>['ibu tador', 'ibunya', 'ibumu', 'ibu']</td>\n",
              "      <td>akan tetapi kalau mengharapkan bantuan sang ib...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>Tokoh-5</td>\n",
              "      <td>['raja margolang']</td>\n",
              "      <td>raja margolang menyetujui saran tersebut</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>Tokoh-11</td>\n",
              "      <td>['sipakpak kunal']</td>\n",
              "      <td>namanya sipakpak kunal</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1845</th>\n",
              "      <td>13</td>\n",
              "      <td>Tokoh-9</td>\n",
              "      <td>['orang anak', 'orang']</td>\n",
              "      <td>berapa orang yang kau kehendaki membawa tapak ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1846</th>\n",
              "      <td>25</td>\n",
              "      <td>Tokoh-1</td>\n",
              "      <td>['ibunya', 'ibu']</td>\n",
              "      <td>sementara itu sang ibu yang tidak tahan lagi m...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>protagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1847</th>\n",
              "      <td>13</td>\n",
              "      <td>Tokoh-8</td>\n",
              "      <td>['datu', 'datu kandibata', 'kandibata']</td>\n",
              "      <td>datu kandibata dan isterinya terus menghemoask...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1848</th>\n",
              "      <td>109</td>\n",
              "      <td>Tokoh-10</td>\n",
              "      <td>['orang']</td>\n",
              "      <td>rumah mereka seperti kebanyakan rumah orang la...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1849</th>\n",
              "      <td>23</td>\n",
              "      <td>Tokoh-12</td>\n",
              "      <td>['nak']</td>\n",
              "      <td>ibu tidak sengaja nak</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>antagonist</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1850 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34d217f8-bef8-4d2b-9a3b-7d7ec0f3b427')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-34d217f8-bef8-4d2b-9a3b-7d7ec0f3b427 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-34d217f8-bef8-4d2b-9a3b-7d7ec0f3b427');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fcbd5e07-38ec-4ec6-af1e-d4d8e250a290\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fcbd5e07-38ec-4ec6-af1e-d4d8e250a290')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fcbd5e07-38ec-4ec6-af1e-d4d8e250a290 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_286e8928-506d-4ed3-b6b5-5dd5f38d946d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_286e8928-506d-4ed3-b6b5-5dd5f38d946d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 1850,\n  \"fields\": [\n    {\n      \"column\": \"story_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40,\n        \"min\": 6,\n        \"max\": 114,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          28,\n          7,\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"person\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 33,\n        \"samples\": [\n          \"Tokoh-27\",\n          \"Tokoh-13\",\n          \"Tokoh-22\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aliases\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 207,\n        \"samples\": [\n          \"['raksasa']\",\n          \"['ramuan', 'nenek', 'ramuan nenek']\",\n          \"['anaknya', 'anakku', 'anak']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subject_sentences\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1847,\n        \"samples\": [\n          \"pada suatu hari sambil mengumpulkan kayu bakar nenek itu bercerita kepada ambun bahwa sebenarnya ia adalah bagian dari keluarga kerajaan sang sambaratih\",\n          \"putroe hitam pun pergi ke belakang rumahnya dan berdoa ya tuhanku jadikanlah aku sebagai pohon enau\",\n          \"akhirnya lahuda dengan puteri raja dibatalkan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_dialogue\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_subject\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count_lexicon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": -6,\n        \"max\": 13,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          6,\n          -6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"protagonist\",\n          \"antagonist\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "def preprocess_text(sentence):\n",
        "    # Lowercasing\n",
        "    sentence = sentence.lower()\n",
        "\n",
        "    # Remove non-alphabetical characters (keep spaces)\n",
        "    sentence = re.sub(r'[^a-zA-Z\\s]', '', sentence)\n",
        "\n",
        "    return sentence\n",
        "\n",
        "train_df['subject_sentences'] = train_df['subject_sentences'].apply(preprocess_text)\n",
        "\n",
        "test_df['subject_sentences'] = test_df['subject_sentences'].apply(preprocess_text)\n",
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmjqhv5x7ufO",
        "outputId": "cf95e5c1-85ab-4dd5-d28a-80e9ade23666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended maxlen: 22\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "lengths = train_df['subject_sentences'].apply(lambda x: len(x.split()))\n",
        "maxlen = int(np.percentile(lengths, 95))  # 95th percentile of token counts\n",
        "print(\"Recommended maxlen:\", maxlen)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ueep1TO7BOv"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "texts = train_df['subject_sentences'].tolist()\n",
        "\n",
        "# Tokenizer setup\n",
        "MAX_NUM_WORDS = 10000\n",
        "MAX_LEN = maxlen\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# Padding\n",
        "X_text = pad_sequences(sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "train_df['f4_encoded'] = [list(seq) for seq in X_text]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UplCvG29xRdd"
      },
      "outputs": [],
      "source": [
        "texts_test = test_df['subject_sentences'].tolist()\n",
        "sequences_test = tokenizer.texts_to_sequences(texts_test)\n",
        "\n",
        "X_text_test = pad_sequences(sequences_test, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "\n",
        "test_df['f4_encoded'] = [list(seq) for seq in X_text_test]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdiSNrxgj3Wd"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM = 300  # Make sure this matches the FastText file, e.g. cc.id.300.vec\n",
        "\n",
        "# Create embedding matrix\n",
        "word_index = tokenizer.word_index\n",
        "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if i >= MAX_NUM_WORDS:\n",
        "        continue\n",
        "    try:\n",
        "        embedding_vector = fasttext_model[word]\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    except KeyError:\n",
        "        pass  # FastText can usually generate vectors for OOV words, but just in case\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RO7Gobw8sdV"
      },
      "source": [
        "#### **PREPROCESS NUMERIC FEATURE**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fReaWyW78x0I"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Step 1: Select the column and reshape to 2D\n",
        "values = train_df[['is_dialogue']]  # double brackets to keep it as a DataFrame (2D)\n",
        "\n",
        "# Step 2: Apply MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaled_values = scaler.fit_transform(values)\n",
        "\n",
        "# Step 3: Replace or add back to the DataFrame\n",
        "train_df['is_dialogue_scaled'] = scaled_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UK_Q-6tyw-kb"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Step 1: Select the column and reshape to 2D\n",
        "values = test_df[['is_dialogue']]  # double brackets to keep it as a DataFrame (2D)\n",
        "\n",
        "# Step 2: Apply MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaled_values = scaler.fit_transform(values)\n",
        "\n",
        "# Step 3: Replace or add back to the DataFrame\n",
        "\n",
        "test_df['is_dialogue_scaled'] = scaled_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbzArgJbO1QE"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Step 1: Select the column and reshape to 2D\n",
        "values = train_df[['is_subject']]  # double brackets to keep it as a DataFrame (2D)\n",
        "\n",
        "# Step 2: Apply MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaled_values = scaler.fit_transform(values)\n",
        "\n",
        "# Step 3: Replace or add back to the DataFrame\n",
        "train_df['is_subject_scaled'] = scaled_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGTruavAxAyF"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Step 1: Select the column and reshape to 2D\n",
        "values = test_df[['is_subject']]  # double brackets to keep it as a DataFrame (2D)\n",
        "\n",
        "# Step 2: Apply MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaled_values = scaler.fit_transform(values)\n",
        "\n",
        "# Step 3: Replace or add back to the DataFrame\n",
        "\n",
        "test_df['is_subject_scaled'] = scaled_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pKFnMgIBh14"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Step 1: Select the column and reshape to 2D\n",
        "values = train_df[['count_lexicon']]  # double brackets to keep it as a DataFrame (2D)\n",
        "\n",
        "# Step 2: Apply MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaled_values = scaler.fit_transform(values)\n",
        "\n",
        "# Step 3: Replace or add ack to the DataFrame\n",
        "train_df['count_lexicon_scaled'] = scaled_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLwMdsrFxDLz"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Step 1: Select the column and reshape to 2D\n",
        "values = test_df[['count_lexicon']]  # double brackets to keep it as a DataFrame (2D)\n",
        "\n",
        "# Step 2: Apply MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaled_values = scaler.fit_transform(values)\n",
        "\n",
        "# Step 3: Replace or add ack to the DataFrame\n",
        "\n",
        "test_df['count_lexicon_scaled'] = scaled_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        },
        "id": "xX1iy0JNBUE8",
        "outputId": "d1e7e018-a34c-46f0-a675-cb6b3a5be68e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      story_id    person                                  aliases  \\\n",
              "0           28  Tokoh-11                                ['ambun']   \n",
              "1           16   Tokoh-4      ['kepala', 'kepala tador', 'tador']   \n",
              "2           16   Tokoh-1  ['ibu tador', 'ibunya', 'ibumu', 'ibu']   \n",
              "3           10   Tokoh-5                       ['raja margolang']   \n",
              "4           10  Tokoh-11                       ['sipakpak kunal']   \n",
              "...        ...       ...                                      ...   \n",
              "1845        13   Tokoh-9                  ['orang anak', 'orang']   \n",
              "1846        25   Tokoh-1                        ['ibunya', 'ibu']   \n",
              "1847        13   Tokoh-8  ['datu', 'datu kandibata', 'kandibata']   \n",
              "1848       109  Tokoh-10                                ['orang']   \n",
              "1849        23  Tokoh-12                                  ['nak']   \n",
              "\n",
              "                                      subject_sentences  is_dialogue  \\\n",
              "0                                ambun kembali bertanya            0   \n",
              "1     tador tidak menyangka kalau dia ditinggal di r...            0   \n",
              "2     akan tetapi kalau mengharapkan bantuan sang ib...            0   \n",
              "3              raja margolang menyetujui saran tersebut            0   \n",
              "4                                namanya sipakpak kunal            1   \n",
              "...                                                 ...          ...   \n",
              "1845  berapa orang yang kau kehendaki membawa tapak ...            0   \n",
              "1846  sementara itu sang ibu yang tidak tahan lagi m...            0   \n",
              "1847  datu kandibata dan isterinya terus menghemoask...            0   \n",
              "1848  rumah mereka seperti kebanyakan rumah orang la...            0   \n",
              "1849                              ibu tidak sengaja nak            1   \n",
              "\n",
              "      is_subject  count_lexicon        label  \\\n",
              "0              1              1  protagonist   \n",
              "1              1              2  protagonist   \n",
              "2              0              1   antagonist   \n",
              "3              0              1       others   \n",
              "4              0              0   antagonist   \n",
              "...          ...            ...          ...   \n",
              "1845           1              1       others   \n",
              "1846           1              2  protagonist   \n",
              "1847           1              1   antagonist   \n",
              "1848           0              0       others   \n",
              "1849           0              0   antagonist   \n",
              "\n",
              "                                             f4_encoded  is_dialogue_scaled  \\\n",
              "0     [125, 50, 188, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...                 0.0   \n",
              "1     [12, 6, 729, 132, 36, 549, 5, 35, 0, 0, 0, 0, ...                 0.0   \n",
              "2     [20, 61, 132, 730, 628, 41, 13, 355, 8, 12, 0,...                 0.0   \n",
              "3     [10, 147, 1211, 1212, 62, 0, 0, 0, 0, 0, 0, 0,...                 0.0   \n",
              "4     [731, 148, 149, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...                 1.0   \n",
              "...                                                 ...                 ...   \n",
              "1845  [711, 15, 2, 144, 3622, 110, 1200, 3623, 20, 3...                 0.0   \n",
              "1846  [133, 3, 41, 13, 2, 6, 1784, 48, 54, 1209, 325...                 0.0   \n",
              "1847  [223, 237, 4, 519, 169, 3626, 280, 183, 603, 2...                 0.0   \n",
              "1848  [35, 14, 57, 3628, 35, 15, 115, 5, 195, 394, 3...                 0.0   \n",
              "1849  [13, 6, 1125, 319, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...                 1.0   \n",
              "\n",
              "      is_subject_scaled  count_lexicon_scaled  \n",
              "0                   1.0              0.368421  \n",
              "1                   1.0              0.421053  \n",
              "2                   0.0              0.368421  \n",
              "3                   0.0              0.368421  \n",
              "4                   0.0              0.315789  \n",
              "...                 ...                   ...  \n",
              "1845                1.0              0.368421  \n",
              "1846                1.0              0.421053  \n",
              "1847                1.0              0.368421  \n",
              "1848                0.0              0.315789  \n",
              "1849                0.0              0.315789  \n",
              "\n",
              "[1850 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e07f3b85-d465-48c8-9c56-ece6e1eb09c1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>story_id</th>\n",
              "      <th>person</th>\n",
              "      <th>aliases</th>\n",
              "      <th>subject_sentences</th>\n",
              "      <th>is_dialogue</th>\n",
              "      <th>is_subject</th>\n",
              "      <th>count_lexicon</th>\n",
              "      <th>label</th>\n",
              "      <th>f4_encoded</th>\n",
              "      <th>is_dialogue_scaled</th>\n",
              "      <th>is_subject_scaled</th>\n",
              "      <th>count_lexicon_scaled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28</td>\n",
              "      <td>Tokoh-11</td>\n",
              "      <td>['ambun']</td>\n",
              "      <td>ambun kembali bertanya</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>protagonist</td>\n",
              "      <td>[125, 50, 188, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.368421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16</td>\n",
              "      <td>Tokoh-4</td>\n",
              "      <td>['kepala', 'kepala tador', 'tador']</td>\n",
              "      <td>tador tidak menyangka kalau dia ditinggal di r...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>protagonist</td>\n",
              "      <td>[12, 6, 729, 132, 36, 549, 5, 35, 0, 0, 0, 0, ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.421053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16</td>\n",
              "      <td>Tokoh-1</td>\n",
              "      <td>['ibu tador', 'ibunya', 'ibumu', 'ibu']</td>\n",
              "      <td>akan tetapi kalau mengharapkan bantuan sang ib...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>antagonist</td>\n",
              "      <td>[20, 61, 132, 730, 628, 41, 13, 355, 8, 12, 0,...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.368421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>Tokoh-5</td>\n",
              "      <td>['raja margolang']</td>\n",
              "      <td>raja margolang menyetujui saran tersebut</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>others</td>\n",
              "      <td>[10, 147, 1211, 1212, 62, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.368421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>Tokoh-11</td>\n",
              "      <td>['sipakpak kunal']</td>\n",
              "      <td>namanya sipakpak kunal</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>antagonist</td>\n",
              "      <td>[731, 148, 149, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.315789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1845</th>\n",
              "      <td>13</td>\n",
              "      <td>Tokoh-9</td>\n",
              "      <td>['orang anak', 'orang']</td>\n",
              "      <td>berapa orang yang kau kehendaki membawa tapak ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>others</td>\n",
              "      <td>[711, 15, 2, 144, 3622, 110, 1200, 3623, 20, 3...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.368421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1846</th>\n",
              "      <td>25</td>\n",
              "      <td>Tokoh-1</td>\n",
              "      <td>['ibunya', 'ibu']</td>\n",
              "      <td>sementara itu sang ibu yang tidak tahan lagi m...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>protagonist</td>\n",
              "      <td>[133, 3, 41, 13, 2, 6, 1784, 48, 54, 1209, 325...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.421053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1847</th>\n",
              "      <td>13</td>\n",
              "      <td>Tokoh-8</td>\n",
              "      <td>['datu', 'datu kandibata', 'kandibata']</td>\n",
              "      <td>datu kandibata dan isterinya terus menghemoask...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>antagonist</td>\n",
              "      <td>[223, 237, 4, 519, 169, 3626, 280, 183, 603, 2...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.368421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1848</th>\n",
              "      <td>109</td>\n",
              "      <td>Tokoh-10</td>\n",
              "      <td>['orang']</td>\n",
              "      <td>rumah mereka seperti kebanyakan rumah orang la...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>others</td>\n",
              "      <td>[35, 14, 57, 3628, 35, 15, 115, 5, 195, 394, 3...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.315789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1849</th>\n",
              "      <td>23</td>\n",
              "      <td>Tokoh-12</td>\n",
              "      <td>['nak']</td>\n",
              "      <td>ibu tidak sengaja nak</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>antagonist</td>\n",
              "      <td>[13, 6, 1125, 319, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.315789</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1850 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e07f3b85-d465-48c8-9c56-ece6e1eb09c1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e07f3b85-d465-48c8-9c56-ece6e1eb09c1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e07f3b85-d465-48c8-9c56-ece6e1eb09c1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-03bae8be-d5e5-43b0-a17c-443403af341d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-03bae8be-d5e5-43b0-a17c-443403af341d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-03bae8be-d5e5-43b0-a17c-443403af341d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_5a744b70-4dc0-4076-81db-06e86862c115\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5a744b70-4dc0-4076-81db-06e86862c115 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 1850,\n  \"fields\": [\n    {\n      \"column\": \"story_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40,\n        \"min\": 6,\n        \"max\": 114,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          28,\n          7,\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"person\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 33,\n        \"samples\": [\n          \"Tokoh-27\",\n          \"Tokoh-13\",\n          \"Tokoh-22\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aliases\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 207,\n        \"samples\": [\n          \"['raksasa']\",\n          \"['ramuan', 'nenek', 'ramuan nenek']\",\n          \"['anaknya', 'anakku', 'anak']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subject_sentences\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1847,\n        \"samples\": [\n          \"pada suatu hari sambil mengumpulkan kayu bakar nenek itu bercerita kepada ambun bahwa sebenarnya ia adalah bagian dari keluarga kerajaan sang sambaratih\",\n          \"putroe hitam pun pergi ke belakang rumahnya dan berdoa ya tuhanku jadikanlah aku sebagai pohon enau\",\n          \"akhirnya lahuda dengan puteri raja dibatalkan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_dialogue\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_subject\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count_lexicon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": -6,\n        \"max\": 13,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          6,\n          -6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"protagonist\",\n          \"antagonist\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f4_encoded\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_dialogue_scaled\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.43171589298062296,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_subject_scaled\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.467636478337127,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count_lexicon_scaled\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07780811008448273,\n        \"min\": 0.0,\n        \"max\": 0.9999999999999999,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.631578947368421,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7bjynrU_f3g"
      },
      "outputs": [],
      "source": [
        "numeric_features = ['is_dialogue_scaled', 'is_subject_scaled', 'count_lexicon_scaled']\n",
        "X_numeric = train_df[numeric_features].values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4ND4iLj9o6A"
      },
      "source": [
        "#### **LABEL ENCODING**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lyf9972F9JkJ",
        "outputId": "185df9ff-0df6-43f6-87a9-b0e777a6ef35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'antagonist': 0, 'others': 1, 'protagonist': 2}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assume your labels are in df['label']\n",
        "le = LabelEncoder()\n",
        "train_df['label_encoded'] = le.fit_transform(train_df['label'])\n",
        "\n",
        "# Optional: check mapping\n",
        "print(dict(zip(le.classes_, le.transform(le.classes_))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8BuxR6xxGfp",
        "outputId": "b7af7f1b-06e9-4276-b14f-3243ee1c8025"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'antagonist': 0, 'others': 1, 'protagonist': 2}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assume your labels are in df['label']\n",
        "le = LabelEncoder()\n",
        "test_df['label_encoded'] = le.fit_transform(test_df['label'])\n",
        "\n",
        "# Optional: check mapping\n",
        "print(dict(zip(le.classes_, le.transform(le.classes_))))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot8LCfT1cSGz"
      },
      "source": [
        "---\n",
        "### **DATA SPLITTING**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdUGS92KPrD-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create the group_key for reference\n",
        "train_df['group_key'] = train_df['story_id'].astype(str) + '_' + train_df['person'].astype(str)\n",
        "\n",
        "# Extract features and labels without splitting\n",
        "X_text_train = np.array(train_df['f4_encoded'].tolist())\n",
        "X_num_train = train_df[['is_dialogue_scaled', 'is_subject_scaled', 'count_lexicon_scaled']].to_numpy()\n",
        "y_train = train_df['label_encoded'].to_numpy()\n",
        "group_keys_train = train_df['group_key'].to_numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yS5WAKa5xKe2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create the group_key for reference\n",
        "test_df['group_key'] = test_df['story_id'].astype(str) + '_' + test_df['person'].astype(str)\n",
        "\n",
        "# Extract test inputs\n",
        "X_text_test = np.array(test_df['f4_encoded'].tolist())\n",
        "X_num_test = test_df[['is_dialogue_scaled', 'is_subject_scaled', 'count_lexicon_scaled']].to_numpy()\n",
        "y_test = test_df['label_encoded'].to_numpy()\n",
        "group_keys_test = test_df['group_key'].to_numpy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2yik8_Hck8R"
      },
      "outputs": [],
      "source": [
        "X_num_test\n",
        "\n",
        "X_num_test_3 = [[row[0], row[1]] for row in X_num_test]\n",
        "X_num_test_2 = [[row[1]] for row in X_num_test]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_num_test_3 = np.array(X_num_test_3)\n",
        "X_num_test_2 = np.array(X_num_test_2)"
      ],
      "metadata": {
        "id": "L4W_fqYWYCxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTxkuYePk4_G"
      },
      "outputs": [],
      "source": [
        "X_num_train\n",
        "\n",
        "X_num_train_3 = [[row[0], row[1]] for row in X_num_train]\n",
        "X_num_train_2 = [[row[1]] for row in X_num_train]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fU7REC-swV2"
      },
      "outputs": [],
      "source": [
        "X_num_train_3 = np.array(X_num_train_3)\n",
        "X_num_train_2 = np.array(X_num_train_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk3FifUrBwIp"
      },
      "source": [
        "---\n",
        "### **ATTENTION LAYER**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4mpGn9UBrE-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, Dense\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(shape=(input_shape[-1], 1),\n",
        "                                 initializer='glorot_uniform',\n",
        "                                 trainable=True,\n",
        "                                 name='attention_weights')\n",
        "        self.b = self.add_weight(shape=(1,),\n",
        "                                 initializer='zeros',\n",
        "                                 trainable=True,\n",
        "                                 name='attention_bias')\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # inputs shape: (batch_size, time_steps, input_dim)\n",
        "        e = tf.nn.tanh(tf.tensordot(inputs, self.W, axes=1) + self.b)  # (batch_size, time_steps, 1)\n",
        "        alpha = tf.nn.softmax(e, axis=1)  # (batch_size, time_steps, 1)\n",
        "        context = inputs * alpha  # (batch_size, time_steps, input_dim)\n",
        "        context_vector = tf.reduce_sum(context, axis=1)  # (batch_size, input_dim)\n",
        "        return context_vector\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n3bEhc8phCE"
      },
      "source": [
        "---\n",
        "### **EVALUATION**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjaDPUirpkEy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "def evaluate_grouped(model_fitted, X_text_test, X_num_test, group_keys_test, y_test):\n",
        "    # Predict probabilities\n",
        "    y_pred_prob = model_fitted.predict({\"text_input\": X_text_test, \"numeric_input\": X_num_test})\n",
        "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "    # Build base DataFrame\n",
        "    df_test = pd.DataFrame({\n",
        "        'group_key': group_keys_test,\n",
        "        'y_true': y_test,\n",
        "        'y_pred': y_pred\n",
        "    })\n",
        "\n",
        "    # Add prediction probabilities as separate columns\n",
        "    prob_cols = [f'prob_{i}' for i in range(y_pred_prob.shape[1])]\n",
        "    df_probs = pd.DataFrame(y_pred_prob, columns=prob_cols)\n",
        "    df_test = pd.concat([df_test, df_probs], axis=1)\n",
        "\n",
        "    # Group and aggregate\n",
        "    grouped = df_test.groupby('group_key').agg({\n",
        "        'y_true': lambda x: Counter(x).most_common(1)[0][0],  # still using majority for true label\n",
        "        **{col: 'mean' for col in prob_cols}\n",
        "    }).reset_index()\n",
        "\n",
        "    # Get predicted label based on highest average probability\n",
        "    grouped['y_pred'] = grouped[prob_cols].values.argmax(axis=1)\n",
        "\n",
        "    # Evaluate\n",
        "    print(classification_report(grouped['y_true'], grouped['y_pred'], digits=4))\n",
        "\n",
        "    precision = precision_score(grouped['y_true'], grouped['y_pred'], average='macro')\n",
        "    recall = recall_score(grouped['y_true'], grouped['y_pred'], average='macro')\n",
        "    f1 = f1_score(grouped['y_true'], grouped['y_pred'], average='macro')\n",
        "    accuracy = accuracy_score(grouped['y_true'], grouped['y_pred'])\n",
        "\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall:    {recall:.4f}\")\n",
        "    print(f\"F1-score:  {f1:.4f}\")\n",
        "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "\n",
        "    cm = confusion_matrix(grouped['y_true'], grouped['y_pred'])\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    disp.plot(cmap='Blues')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmcJcFUVUAP3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "def evaluate_single(model_fitted, X_text_test, group_keys_test, y_test):\n",
        "  # 1. Predict\n",
        "  # Predict class probabilities\n",
        "  y_pred_prob = model_fitted.predict(X_text_test)\n",
        "\n",
        "  # Get predicted class (index of max prob)\n",
        "  y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "  # 2. Create a DataFrame to hold predictions, true labels, and group keys\n",
        "  df_test = pd.DataFrame({\n",
        "      'group_key': group_keys_test,\n",
        "      'y_true': y_test,\n",
        "      'y_pred': y_pred\n",
        "  })\n",
        "\n",
        "  # 3. Define a helper function to get the most common label (majority vote)\n",
        "  def most_common_label(labels):\n",
        "      return Counter(labels).most_common(1)[0][0]\n",
        "\n",
        "  # 4. Group by group_key and get majority vote of predictions and true labels\n",
        "  grouped = df_test.groupby('group_key').agg({\n",
        "      'y_pred': lambda x: most_common_label(list(x)),\n",
        "      'y_true': lambda x: most_common_label(list(x))\n",
        "  }).reset_index()\n",
        "\n",
        "  # 5. Compute metrics on grouped labels\n",
        "  print(classification_report(grouped['y_true'], grouped['y_pred'], digits=4))\n",
        "\n",
        "  precision = precision_score(grouped['y_true'], grouped['y_pred'], average='macro')\n",
        "  recall = recall_score(grouped['y_true'], grouped['y_pred'], average='macro')\n",
        "  f1 = f1_score(grouped['y_true'], grouped['y_pred'], average='macro')\n",
        "  accuracy = accuracy_score(grouped['y_true'], grouped['y_pred'])\n",
        "\n",
        "  print(f\"Precision: {precision:.4f}\")\n",
        "  print(f\"Recall:    {recall:.4f}\")\n",
        "  print(f\"F1-score:  {f1:.4f}\")\n",
        "  print(f\"Accuracy:  {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgJORUeqeakr"
      },
      "source": [
        "---\n",
        "## **4 FEATURE**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTX-GBxV6Zts",
        "outputId": "61d43709-ca09-46e1-ac9f-7541ce61a654"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1850"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "len(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zatM5G6uW672"
      },
      "source": [
        "---\n",
        "### **LSTM (4 FEATURE)**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Nk-QgZ1dB0oi",
        "outputId": "72b912e8-7e98-4eff-f7b3-221bd1316f89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ text_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_6         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m1,089,000\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m93,440\u001b[0m │ embedding_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ numeric_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer_6   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m65\u001b[0m │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │         \u001b[38;5;34m12\u001b[0m │ numeric_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ attention_layer_… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,352\u001b[0m │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m195\u001b[0m │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ text_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,089,000</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">93,440</span> │ embedding_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ numeric_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer_6   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │ numeric_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_layer_… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,187,320\u001b[0m (4.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,187,320</span> (4.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,187,186\u001b[0m (4.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,187,186</span> (4.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m134\u001b[0m (536.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134</span> (536.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 64ms/step - accuracy: 0.3576 - loss: 1.5472 - val_accuracy: 0.3730 - val_loss: 1.1638\n",
            "Epoch 2/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.3357 - loss: 1.4441 - val_accuracy: 0.4000 - val_loss: 1.1555\n",
            "Epoch 3/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.3785 - loss: 1.3243 - val_accuracy: 0.4000 - val_loss: 1.1424\n",
            "Epoch 4/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.3654 - loss: 1.3307 - val_accuracy: 0.4595 - val_loss: 1.1319\n",
            "Epoch 5/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.3815 - loss: 1.2555 - val_accuracy: 0.4432 - val_loss: 1.1199\n",
            "Epoch 6/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 60ms/step - accuracy: 0.3691 - loss: 1.2671 - val_accuracy: 0.4432 - val_loss: 1.1097\n",
            "Epoch 7/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 67ms/step - accuracy: 0.3954 - loss: 1.2166 - val_accuracy: 0.4703 - val_loss: 1.0916\n",
            "Epoch 8/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 83ms/step - accuracy: 0.4389 - loss: 1.1941 - val_accuracy: 0.4973 - val_loss: 1.0691\n",
            "Epoch 9/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.4893 - loss: 1.1512 - val_accuracy: 0.5351 - val_loss: 1.0293\n",
            "Epoch 10/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 60ms/step - accuracy: 0.5365 - loss: 1.0871 - val_accuracy: 0.5946 - val_loss: 0.9560\n",
            "Epoch 11/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.5938 - loss: 0.9772 - val_accuracy: 0.6595 - val_loss: 0.8715\n",
            "Epoch 12/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.6415 - loss: 0.8966 - val_accuracy: 0.6703 - val_loss: 0.8352\n",
            "Epoch 13/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.6817 - loss: 0.8100 - val_accuracy: 0.6973 - val_loss: 0.7878\n",
            "Epoch 14/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.7499 - loss: 0.6935 - val_accuracy: 0.6865 - val_loss: 0.7906\n",
            "Epoch 15/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - accuracy: 0.7644 - loss: 0.6525 - val_accuracy: 0.7189 - val_loss: 0.7656\n",
            "Epoch 16/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.8147 - loss: 0.5449 - val_accuracy: 0.6973 - val_loss: 0.7991\n",
            "Epoch 17/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.7946 - loss: 0.5427 - val_accuracy: 0.6973 - val_loss: 0.8093\n",
            "Epoch 18/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - accuracy: 0.8181 - loss: 0.5430 - val_accuracy: 0.7243 - val_loss: 0.7976\n",
            "Epoch 19/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.8368 - loss: 0.4818 - val_accuracy: 0.7081 - val_loss: 0.8003\n",
            "Epoch 20/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - accuracy: 0.8316 - loss: 0.4676 - val_accuracy: 0.6973 - val_loss: 0.8304\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Concatenate, Input, Embedding, LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "\n",
        "# Jumlah fitur numerik kamu\n",
        "# Jumlah fitur numerik kamu\n",
        "NUM_NUMERIC_FEATURES = train_df[['is_dialogue_scaled', 'is_subject_scaled', 'count_lexicon_scaled']].shape[1]\n",
        "\n",
        "# --- TEXT INPUT BRANCH ---\n",
        "text_input = Input(shape=(MAX_LEN,), name=\"text_input\")\n",
        "x_text = Embedding(\n",
        "    input_dim=num_words,\n",
        "    output_dim=EMBEDDING_DIM,\n",
        "    weights=[embedding_matrix],\n",
        "    input_length=MAX_LEN,\n",
        "    trainable=True\n",
        ")(text_input)\n",
        "\n",
        "x_text = LSTM(\n",
        "    64,                      # lebih besar kapasitas\n",
        "    return_sequences=True,\n",
        "    dropout=0.4,             # sedikit diturunkan\n",
        "    recurrent_dropout=0.4,\n",
        ")(x_text)\n",
        "\n",
        "x_text = AttentionLayer()(x_text)\n",
        "\n",
        "# --- NUMERIC INPUT BRANCH ---\n",
        "numeric_input = Input(shape=(NUM_NUMERIC_FEATURES,), name=\"numeric_input\")\n",
        "\n",
        "# Optional: normalization/dense layer\n",
        "x_numeric = BatchNormalization()(numeric_input)\n",
        "\n",
        "# --- CONCATENATE BOTH ---\n",
        "x = Concatenate()([x_text, x_numeric])\n",
        "\n",
        "# Fully connected layers\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# Output\n",
        "output = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Build model\n",
        "model_lstm = Model(inputs=[text_input, numeric_input], outputs=output)\n",
        "model_lstm.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_lstm.summary()\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "history = model_lstm.fit(\n",
        "    {\"text_input\": X_text_train, \"numeric_input\": X_num_train},\n",
        "    y_train,\n",
        "    validation_split=0.1,\n",
        "    shuffle=True,\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    callbacks=[early_stopping],\n",
        "    class_weight=class_weights_dict\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        },
        "id": "f1NICf8Yjwkn",
        "outputId": "8c6eb0ff-485e-4db0-995d-fe3e5dc758b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8148    0.7333    0.7719        30\n",
            "           1     0.8256    0.8452    0.8353        84\n",
            "           2     0.6818    0.6977    0.6897        43\n",
            "\n",
            "    accuracy                         0.7834       157\n",
            "   macro avg     0.7741    0.7587    0.7656       157\n",
            "weighted avg     0.7841    0.7834    0.7833       157\n",
            "\n",
            "Precision: 0.7741\n",
            "Recall:    0.7587\n",
            "F1-score:  0.7656\n",
            "Accuracy:  0.7834\n",
            "Confusion Matrix:\n",
            " [[22  5  3]\n",
            " [ 2 71 11]\n",
            " [ 3 10 30]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAGxCAYAAACZXTQSAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOHJJREFUeJzt3Xl8VPXZ///3JJBJIAsESUIkwSCYgGwKiCmCoAGkLYJw16VQI4L9KgkKCAo/y+oSl1oUDWARCaCURQUBFYpRNgVuCeItihEQTRASQcgKWcjM7w9k2hHQTGYms5zXk8d5PJzP2a6I5prrOp9zjslqtVoFAAB8UoCnAwAAAHVHIgcAwIeRyAEA8GEkcgAAfBiJHAAAH0YiBwDAh5HIAQDwYSRyAAB8WANPB+AMi8Wio0ePKiwsTCaTydPhAAAcZLVaVVpaqtjYWAUEuK+2rKioUFVVldPHCQoKUnBwsAsich2fTuRHjx5VXFycp8MAADgpPz9fLVu2dMuxKyoqFBLWTDp72uljxcTE6PDhw16VzH06kYeFhUmSXs/eq0ahYR6OBu52bXxTT4eAehTUgCt/RlBaWqLE1vG23+fuUFVVJZ09LXP7VCkwqO4HqqlSwVeLVVVVVatEfsUVV+j777+/YHzMmDHKzMxURUWFHn74YS1fvlyVlZUaMGCA5s6dq+joaIfC8ulEfr6d3ig0TI1J5H4vPDzc0yGgHpHIjaVeLo82CJbJiURuNTn23+Snn36qmpoa2+d9+/apX79++tOf/iRJGj9+vN59912tWrVKERERSk9P19ChQ/Xxxx87dB6fTuQAANSaSZIzXxgc3LV58+Z2n59++mldeeWVuvHGG1VcXKyFCxdq2bJluummmyRJixYtUrt27bRz505df/31tT4PX3kBAMZgCnB+kVRSUmK3VFZW/uapq6qq9Prrr+vee++VyWRSTk6OqqurlZKSYtsmKSlJ8fHx2rFjh0M/FokcAAAHxMXFKSIiwrZkZGT85j5r1qxRUVGR7rnnHklSQUGBgoKC1KRJE7vtoqOjVVBQ4FA8tNYBAMZgMjnZWj+3b35+vt2cHbPZ/Ju7Lly4UAMHDlRsbGzdz38JJHIAgDH8V3u8zvvr3MRbRybffv/99/rggw/09ttv28ZiYmJUVVWloqIiu6q8sLBQMTExDoVFax0AADdatGiRoqKi9Ic//ME21rVrVzVs2FDZ2dm2sdzcXOXl5Sk5Odmh41ORAwCMwUWtdUdYLBYtWrRIqampatDgPyk3IiJCo0aN0oQJExQZGanw8HCNHTtWycnJDs1Yl0jkAADDcLK1Xocm9gcffKC8vDzde++9F6ybPXu2AgICNGzYMLsHwjiKRA4AgJv0799fVqv1ouuCg4OVmZmpzMxMp85BIgcAGIMHWuv1gUQOADAGF81a9zbeGRUAAKgVKnIAgDHQWgcAwIf5aWudRA4AMAY/rci98+sFAACoFSpyAIAx0FoHAMCHmUxOJnJa6wAAwMWoyAEAxhBgOrc4s78XIpEDAIzBT6+Re2dUAACgVqjIAQDG4Kf3kZPIAQDGQGsdAAB4GypyAIAx0FoHAMCH+WlrnUQOADAGP63IvfPrBQAAqBUqcgCAMdBaBwDAh9FaBwAA3oaKHABgEE621r209iWRAwCMgdY6AADwNlTkAABjMJmcnLXunRU5iRwAYAx+evuZd0YFAABqhYocAGAMfjrZjUQOADAGP22tk8gBAMbgpxW5d369AAAAtUJFDgAwBlrrAAD4MFrrAADA21CRAwAMwWQyyeSHFTmJHABgCP6ayGmtAwDgw6jIAQDGYPp5cWZ/L0QiBwAYAq11AADgdajIAQCGQEUOAIAPO5/InVkc9cMPP2jEiBFq1qyZQkJC1LFjR+3evdu23mq1atq0aWrRooVCQkKUkpKiAwcOOHQOKnIv9eY727Rj99c6cvSEzEENlNQ2TnffmaKWsZdJkkrLzuhfb32kz774VidOFCs8vJF6dE3S8D/1VeNGwR6OHs76+8L39Y/XNtiNXRkfpW3/esxDEcFdXntrm7Le3q68oyclSUmtYzRx1C1K+d3VHo7M/9R3RX7q1Cn17NlTffv21fvvv6/mzZvrwIEDatq0qW2bZ599VnPmzNHixYuVkJCgqVOnasCAAfrqq68UHFy73+VekcgzMzP13HPPqaCgQJ07d9ZLL72k6667ztNhedS+r7/X71O6q+2VsaqpsWjpyg814+nX9fKzYxQcHKSTp0p18lSZRv65n+Iub67jJ4o177X1OnmqVJPH3e7p8OECiQkxWvFimu1zYCANNH8UG9VEU8fcqtZxzWWVtOLdXfrLpAX6aOmjSmrdwtPhwQnPPPOM4uLitGjRIttYQkKC7Z+tVqteeOEF/e1vf9PgwYMlSUuWLFF0dLTWrFmjO++8s1bn8fhvhhUrVmjChAmaPn269uzZo86dO2vAgAH68ccfPR2aR814dIRuvrGL4ltGKaFVjB76f4N1/KdiHTp8TJLUKi5Kk8fdruuuTVSL6Eh1ujpBI26/SZ9+9o1qaiwejh6uEBgYqKhm4balWZNQT4cEN7ilV0f163m1royPUpv4KD32wCA1bmTW7n3feTo0/2NywSKppKTEbqmsrLzo6dauXatu3brpT3/6k6KionTNNddowYIFtvWHDx9WQUGBUlJSbGMRERHq0aOHduzYUesfy+OJ/B//+Ifuu+8+jRw5Uu3bt9f8+fPVqFEjvfbaa54OzaucPn3uP5TQ0JBLblN+ulKNQsxUbn7i8JHjuubWqbr+T7OUNmOJjhSc9HRIcLOaGove/neOTp+pUvcOV3g6HL/jqmvkcXFxioiIsC0ZGRkXPd+3336refPmqW3bttq4caMeeOABPfjgg1q8eLEkqaCgQJIUHR1tt190dLRtXW14tLVeVVWlnJwcTZkyxTYWEBCglJQUh76N+DuLxapXl25Qu6vi1Cou6qLblJSe1srVW9X/pmvrOTq4w7XtW+mFx/6sK+Oj9ONPJXr+tQ26bcwcfbR0skIbMwfC33x18KgGjn5eFVVn1TjErMXPjFYibXWvlZ+fr/DwcNtns9l80e0sFou6deump556SpJ0zTXXaN++fZo/f75SU1NdFo9HS7cTJ06opqam1t9GKisrL2hpGMErWe8q78iPmpj+Pxddf/p0pWY9t0xxlzfXXUP71G9wcIubkttr0E3XqH2by9WnRzu9/vf/p5KyM1r74WeeDg1u0KZVlD5aOlkbFz6skUNvUPqs15X77TFPh+V3zr3F1JmK/NxxwsPD7ZZLJfIWLVqoffv2dmPt2rVTXl6eJCkmJkaSVFhYaLdNYWGhbV1t+FQPNiMjw66dERcX5+mQ3O6VrPf06WcH9MRjqbqsWfgF60+fqdSMZ19XSHCQpoy/Qw0aBHogSrhbRFgjtY5rru+OnPB0KHCDoIYN1Dquubq0i9fUtFt1ddtYvbJii6fD8jsmOdlad/AZrT179lRubq7d2DfffKNWrVpJOjfxLSYmRtnZ2bb1JSUl2rVrl5KTk2t9Ho8m8ssuu0yBgYG1/jYyZcoUFRcX25b8/Pz6CrXeWa1WvZL1nnbu/lpPPHa3oqOaXrDN6dOVmvH062rYIFB/e/guBQV5xU0IcIPy05X6/oefFHXZhV/m4H8sFquqqqs9HQacNH78eO3cuVNPPfWUDh48qGXLlumf//yn0tLO3Y1iMpk0btw4PfHEE1q7dq2++OIL3X333YqNjdWQIUNqfR6P/uYPCgpS165dlZ2dbQvaYrEoOztb6enpF2xvNpsv2cLwN69kvaetn3yh/2/CnQoJNutUUZkkqVEjs8xBDXX6dKWmP71UlVXVGj/mDp0+U6nTZ85NiAsPb6TAAJ9qtuAXZr68Rv17dlDLmKYqOFGiv7/6ngICTbotpaunQ4OLPZ65Vjf/rr1aRjdV2elKvbVxtz7ec1CrXhzj6dD8Tn3fR969e3etXr1aU6ZM0axZs5SQkKAXXnhBw4cPt23zyCOPqLy8XH/9619VVFSkG264QRs2bKj1PeSSF9xHPmHCBKWmpqpbt2667rrr9MILL6i8vFwjR470dGge9f4H557889gTi+3GH/zrYN18Yxcd+u6Yvjn0gyTp/gkv2W3zzxceUnTzJvUSJ9zj2I9FGjN9sU6VlKtZk1B179Ra61+ZoGZNuQXN35w4Vaq0mUtVeKJE4aHBat8mVqteHKM+PZI8HZr/8cDbz/74xz/qj3/846UPaTJp1qxZmjVrVp3D8ngiv+OOO3T8+HFNmzZNBQUF6tKlizZs2HDBBDijeeeN6b+6vmP7K35zG/iu+bPu8XQIqCcv/m34b28E/AqPJ3JJSk9Pv2grHQAAl3GytW710pemeEUiBwDA3Zy9Ru7U9XU3IpEDAAzBXxM5U5sBAPBhVOQAAGPwwKz1+kAiBwAYAq11AADgdajIAQCG4K8VOYkcAGAI/prIaa0DAODDqMgBAIbgrxU5iRwAYAx+evsZrXUAAHwYFTkAwBBorQMA4MNI5AAA+DB/TeRcIwcAwIdRkQMAjMFPZ62TyAEAhkBrHQAAeB0qcgCAIfhrRU4iBwAYgklOJnIvvUhOax0AAB9GRQ4AMARa6wAA+DI/vf2M1joAAD6MihwAYAi01gEA8GEkcgAAfJjJdG5xZn9vxDVyAAB8GBU5AMAQzlXkzrTWXRiMC5HIAQDG4GRrndvPAACAy1GRAwAMgVnrAAD4MGatAwAAr0NFDgAwhIAAkwIC6l5WW53Y151I5AAAQ6C1DgAAvA4VOQDAEJi1DgCAD6O1DgCADztfkTuzOGLGjBkX7J+UlGRbX1FRobS0NDVr1kyhoaEaNmyYCgsLHf65SOQAALjJ1VdfrWPHjtmW7du329aNHz9e69at06pVq7RlyxYdPXpUQ4cOdfgctNYBAIbgiWvkDRo0UExMzAXjxcXFWrhwoZYtW6abbrpJkrRo0SK1a9dOO3fu1PXXX1/rc1CRAwAM4fw1cmcWRx04cECxsbFq3bq1hg8frry8PElSTk6OqqurlZKSYts2KSlJ8fHx2rFjh0PnoCIHAMABJSUldp/NZrPMZvMF2/Xo0UNZWVlKTEzUsWPHNHPmTPXq1Uv79u1TQUGBgoKC1KRJE7t9oqOjVVBQ4FA8JHIAgCGY5GRr/ef3mMbFxdmNT58+XTNmzLhg+4EDB9r+uVOnTurRo4datWqllStXKiQkpM5x/BKJHABgCK66/Sw/P1/h4eG28YtV4xfTpEkTXXXVVTp48KD69eunqqoqFRUV2VXlhYWFF72m/mu4Rg4AgAPCw8Ptltom8rKyMh06dEgtWrRQ165d1bBhQ2VnZ9vW5+bmKi8vT8nJyQ7FQ0UOADCE+p61PnHiRA0aNEitWrXS0aNHNX36dAUGBuquu+5SRESERo0apQkTJigyMlLh4eEaO3askpOTHZqxLpHIAQAGUd9Pdjty5Ijuuusu/fTTT2revLluuOEG7dy5U82bN5ckzZ49WwEBARo2bJgqKys1YMAAzZ071+G4SOQAALjB8uXLf3V9cHCwMjMzlZmZ6dR5SOQAAEPgpSkAAPgwf31pCokcAGAI/lqRc/sZAAA+zC8q8p5tLrO7OR/+qWn3dE+HgHr05b+f83QIqAelpRX1dzInW+vyzoLcPxI5AAC/hdY6AADwOlTkAABDYNY6AAA+jNY6AADwOlTkAABDoLUOAIAPo7UOAAC8DhU5AMAQ/LUiJ5EDAAyBa+QAAPgwf63IuUYOAIAPoyIHABgCrXUAAHwYrXUAAOB1qMgBAIZgkpOtdZdF4lokcgCAIQSYTApwIpM7s6870VoHAMCHUZEDAAyBWesAAPgwf521TiIHABhCgOnc4sz+3ohr5AAA+DAqcgCAMZicbI97aUVOIgcAGIK/TnajtQ4AgA+jIgcAGILp5z/O7O+NSOQAAENg1joAAPA6VOQAAEMw9ANh1q5dW+sD3nrrrXUOBgAAd/HXWeu1SuRDhgyp1cFMJpNqamqciQcAADigVoncYrG4Ow4AANzKX19j6tQ18oqKCgUHB7sqFgAA3MZfW+sOz1qvqanR448/rssvv1yhoaH69ttvJUlTp07VwoULXR4gAACucH6ymzOLN3I4kT/55JPKysrSs88+q6CgINt4hw4d9Oqrr7o0OAAA8OscTuRLlizRP//5Tw0fPlyBgYG28c6dO+vrr792aXAAALjK+da6M4s3cvga+Q8//KA2bdpcMG6xWFRdXe2SoAAAcDV/nezmcEXevn17bdu27YLxN998U9dcc41LggIAALXjcCKfNm2a0tPT9cwzz8hisejtt9/WfffdpyeffFLTpk1zR4wAADjN5IKlrp5++mmZTCaNGzfONlZRUaG0tDQ1a9ZMoaGhGjZsmAoLCx0+tsOJfPDgwVq3bp0++OADNW7cWNOmTdP+/fu1bt069evXz+EAAACoD56atf7pp5/qlVdeUadOnezGx48fr3Xr1mnVqlXasmWLjh49qqFDhzp8/DrdR96rVy9t2rSpLrsCAGAYZWVlGj58uBYsWKAnnnjCNl5cXKyFCxdq2bJluummmyRJixYtUrt27bRz505df/31tT5Hnd9+tnv3bi1dulRLly5VTk5OXQ8DAEC9OP8aU2cWSSopKbFbKisrL3nOtLQ0/eEPf1BKSordeE5Ojqqrq+3Gk5KSFB8frx07djj0czlckR85ckR33XWXPv74YzVp0kSSVFRUpN/97ndavny5WrZs6eghAQBwO1e9/SwuLs5ufPr06ZoxY8YF2y9fvlx79uzRp59+esG6goICBQUF2fLoedHR0SooKHAoLocr8tGjR6u6ulr79+/XyZMndfLkSe3fv18Wi0WjR4929HAAAPiU/Px8FRcX25YpU6ZcdJuHHnpIb7zxhtsfZe5wRb5lyxZ98sknSkxMtI0lJibqpZdeUq9evVwaHAAAruSKW8HDw8MVHh7+q9vk5OToxx9/1LXXXmsbq6mp0datW/Xyyy9r48aNqqqqUlFRkV1VXlhYqJiYGIficTiRx8XFXfTBLzU1NYqNjXX0cAAA1AtXtdZr4+abb9YXX3xhNzZy5EglJSXp0UcfVVxcnBo2bKjs7GwNGzZMkpSbm6u8vDwlJyc7FJfDify5557T2LFjlZmZqW7dukk6N/HtoYce0t///ndHDwcAQL347wlrdd2/tsLCwtShQwe7scaNG6tZs2a28VGjRmnChAmKjIxUeHi4xo4dq+TkZIdmrEu1TORNmza1+yZSXl6uHj16qEGDc7ufPXtWDRo00L333qshQ4Y4FAAAAEY0e/ZsBQQEaNiwYaqsrNSAAQM0d+5ch49Tq0T+wgsvOHxgAAC8SX221i9m8+bNdp+Dg4OVmZmpzMxMp45bq0Semprq1EkAAPA0Zx+z6p2vTKnjk93Oq6ioUFVVld3Yb83kAwAAruNwIi8vL9ejjz6qlStX6qeffrpgfU1NjUsCAwDAlXiN6c8eeeQRffjhh5o3b57MZrNeffVVzZw5U7GxsVqyZIk7YgQAwGkmk/OLN3K4Il+3bp2WLFmiPn36aOTIkerVq5fatGmjVq1a6Y033tDw4cPdEScAALgIhyvykydPqnXr1pLOXQ8/efKkJOmGG27Q1q1bXRsdAAAu4qnXmLqbwxV569atdfjwYcXHxyspKUkrV67Uddddp3Xr1l3w8He4zj8WbdT6jz7Xge8LFWxuqOs6tdaM9MFqe0W0p0ODkz5/Z6biY5tdMP7qqq2a9OxKpd7WU/8zoJs6JbZUeGiIWvWdpJKyMx6IFK6w+/++1WurNuurAz/o+MkSzZmeqpt7/ufBIZu2f6GV63foywM/qLj0tN6cN07trrzcgxH7D2fb416axx2vyEeOHKnPP/9ckjR58mRlZmYqODhY48eP16RJkxw61tatWzVo0CDFxsbKZDJpzZo1joZjGJ/sOajRf+qtf782UW+/nK7qszUaOvZllZ+59Ovz4BtuSn1OibdMsS1D0l6SJK354DNJUkhwQ2Xv+Eqzs/7tyTDhImcqqpTYOlZ/Sx9yyfXXdEjQhNG/r9/A4LMcrsjHjx9v++eUlBR9/fXXysnJUZs2bdSpUyeHjlVeXq7OnTvr3nvv1dChQx0NxVDefCnN7vPc6SPUtv8U7d2fr57XtvFQVHCFn4rK7D6PS+2gb/OP6+M9ByRJ8/+1WZLU89q29R0a3KDXdUnqdV3SJdffmtJVkvRDwcn6Cskw/HXWulP3kUtSq1at1KpVqzrtO3DgQA0cONDZEAyppKxCktQ0vJGHI4ErNWwQqNsHdtfcNz70dCiA3/HX1nqtEvmcOXNqfcAHH3ywzsGgdiwWi6b840316Nxa7dvwxjl/8oc+nRQRGqJl63d5OhTA73j6Ea3uUqtEPnv27FodzGQyuTWRV1ZWqrLyP9eES0pK3HYubzbx2ZXaf+iY3l8w/rc3hk8Zcevv9MGOr1RwotjToQDwEbVK5IcPH3Z3HLWSkZGhmTNnejoMj5r07Ept3LZP7/1znC6PburpcOBCcTFN1ee6RP3lkQWeDgXwSwGqwwzvX+zvjbw1rouaMmWKiouLbUt+fr6nQ6o3VqtVk55dqXc3f6618x5Uq8sv83RIcLE/D0rW8VOl+vfHX3o6FMAvcR+5FzCbzTKbzZ4OwyMmPrNSb27crWV//6tCGwWr8MS5ywrhocEKCQ7ycHRwlslk0vBB12v5u7tUU2OxWxfVLExRzcLVOu7cl7er28Sq9HSFjhScUlHJaU+ECyeUn6lU3tETts9HCk5q/6EfFBHWSLFRTVVUclrHjp/S8Z/O/T/+Xf5xSdJlTcPUPJKXUuFCHk3kZWVlOnjwoO3z4cOHtXfvXkVGRio+Pt6DkXmf197aJkn64/0v2o1nThuhPw+63hMhwYX6XJeouBaRen3tzgvWjRzaS5P/+p97it/7eW7EmJlL9S8mxfmcL785opGT5ts+P/vKOknS4H5d9dSkO/XRzi/1t7+vtK2f+NQbkqQxI/op7e7+9RusnzGZpAA/nLVuslqtVk+dfPPmzerbt+8F46mpqcrKyvrN/UtKShQREaHCn4p5faoBNO2e7ukQUI++/Pdzng4B9aC0tERdroxRcbH7fo+fzxVj/vWpzI1C63ycytNlmntXd7fGWhcercj79OkjD36PAADA59Vpstu2bds0YsQIJScn64cffpAkLV26VNu3b3dpcAAAuIq/TnZzOJG/9dZbGjBggEJCQvTZZ5/Z7usuLi7WU0895fIAAQBwhQCT84s3cjiRP/HEE5o/f74WLFighg0b2sZ79uypPXv2uDQ4AADw6xy+Rp6bm6vevXtfMB4REaGioiJXxAQAgMv567PWHa7IY2Ji7G4ZO2/79u1q3bq1S4ICAMDVzr/9zJnFGzmcyO+77z499NBD2rVrl0wmk44ePao33nhDEydO1AMPPOCOGAEAcFqACxZv5HBrffLkybJYLLr55pt1+vRp9e7dW2azWRMnTtTYsWPdESMAALgEhxO5yWTSY489pkmTJungwYMqKytT+/btFRpa95vsAQBwN3+9Rl7nB8IEBQWpffv2rowFAAC3CZBz17kD5J2Z3OFE3rdv31+9Kf7DDz90KiAAAFB7DifyLl262H2urq7W3r17tW/fPqWmproqLgAAXIrW+s9mz5590fEZM2aorKzM6YAAAHAHZ5/O5jdPdruUESNG6LXXXnPV4QAAQC247O1nO3bsUHBwsKsOBwCAS517H3ndy2q/aa0PHTrU7rPVatWxY8e0e/duTZ061WWBAQDgSlwj/1lERITd54CAACUmJmrWrFnq37+/ywIDAAC/zaFEXlNTo5EjR6pjx45q2rSpu2ICAMDlmOwmKTAwUP379+ctZwAAn2NywR9v5PCs9Q4dOujbb791RywAALjN+YrcmcUbOZzIn3jiCU2cOFHr16/XsWPHVFJSYrcAAID6U+tr5LNmzdLDDz+s3//+95KkW2+91e5RrVarVSaTSTU1Na6PEgAAJ/nrNfJaJ/KZM2fq/vvv10cffeTOeAAAcAuTyfSr7wqpzf7eqNaJ3Gq1SpJuvPFGtwUDAAAc49DtZ976bQQAgN/ir611hya7XXXVVYqMjPzVBQAAb3T+yW7OLI6YN2+eOnXqpPDwcIWHhys5OVnvv/++bX1FRYXS0tLUrFkzhYaGatiwYSosLHT453KoIp85c+YFT3YDAAAXatmypZ5++mm1bdtWVqtVixcv1uDBg/XZZ5/p6quv1vjx4/Xuu+9q1apVioiIUHp6uoYOHaqPP/7YofM4lMjvvPNORUVFOXQCAAC8QYDJ5NRLUxzdd9CgQXafn3zySc2bN087d+5Uy5YttXDhQi1btkw33XSTJGnRokVq166ddu7cqeuvv772cdV2Q66PAwB8mScfCFNTU6Ply5ervLxcycnJysnJUXV1tVJSUmzbJCUlKT4+Xjt27HDo2A7PWgcAwMh++fAzs9kss9l80W2/+OILJScnq6KiQqGhoVq9erXat2+vvXv3KigoSE2aNLHbPjo6WgUFBQ7FU+uK3GKx0FYHAPguZye6/VyRx8XFKSIiwrZkZGRc8pSJiYnau3evdu3apQceeECpqan66quvXPpjOfwaUwAAfFGATApw4sUn5/fNz89XeHi4bfxS1bgkBQUFqU2bNpKkrl276tNPP9WLL76oO+64Q1VVVSoqKrKrygsLCxUTE+NgXAAAGICrbj87fzvZ+eXXEvkvWSwWVVZWqmvXrmrYsKGys7Nt63Jzc5WXl6fk5GSHfi4qcgAA3GDKlCkaOHCg4uPjVVpaqmXLlmnz5s3auHGjIiIiNGrUKE2YMEGRkZEKDw/X2LFjlZyc7NCMdYlEDgAwiPp+stuPP/6ou+++W8eOHVNERIQ6deqkjRs3ql+/fpKk2bNnKyAgQMOGDVNlZaUGDBiguXPnOhwXiRwAYAj1fR/5woULf3V9cHCwMjMzlZmZWeeYJK6RAwDg06jIAQCGUJfnpf9yf29EIgcAGEKAnGytO3HrmjvRWgcAwIdRkQMADIHWOgAAPixAzrWhvbWF7a1xAQCAWqAiBwAYgslkcuqV3N76Om8SOQDAEP7rBWZ13t8bkcgBAIZQ3092qy9cIwcAwIdRkQMADMM7a2rnkMgBAIbgr/eR01oHAMCHUZEDAAyB288AAPBhPNkNAAB4HSpyAIAh0FoHAMCH+euT3WitAwDgw/yiIq+xWFVjsXo6DLjZ1x/83dMhoB6t3X/M0yGgHpwpL623c9FaBwDAh/nrrHUSOQDAEPy1IvfWLxgAAKAWqMgBAIbgr7PWSeQAAEPgpSkAAMDrUJEDAAwhQCYFONEgd2ZfdyKRAwAMgdY6AADwOlTkAABDMP38x5n9vRGJHABgCLTWAQCA16EiBwAYgsnJWeu01gEA8CB/ba2TyAEAhuCviZxr5AAA+DAqcgCAIXD7GQAAPizAdG5xZn9vRGsdAAAfRkUOADAEWusAAPgwZq0DAACvQyIHABiCSf9pr9ftj2MyMjLUvXt3hYWFKSoqSkOGDFFubq7dNhUVFUpLS1OzZs0UGhqqYcOGqbCw0KHzkMgBAIZwfta6M4sjtmzZorS0NO3cuVObNm1SdXW1+vfvr/Lycts248eP17p167Rq1Spt2bJFR48e1dChQx06D9fIAQBwgw0bNth9zsrKUlRUlHJyctS7d28VFxdr4cKFWrZsmW666SZJ0qJFi9SuXTvt3LlT119/fa3OQ0UOADAE59rq/2mul5SU2C2VlZW1On9xcbEkKTIyUpKUk5Oj6upqpaSk2LZJSkpSfHy8duzYUeufi0QOADCE87PWnVkkKS4uThEREbYlIyPjN89tsVg0btw49ezZUx06dJAkFRQUKCgoSE2aNLHbNjo6WgUFBbX+uWitAwAMwfTz4sz+kpSfn6/w8HDbuNls/s1909LStG/fPm3fvt2JCC6ORA4AgAPCw8PtEvlvSU9P1/r167V161a1bNnSNh4TE6OqqioVFRXZVeWFhYWKiYmp9fFprQMADCFAJgWYnFgcrOetVqvS09O1evVqffjhh0pISLBb37VrVzVs2FDZ2dm2sdzcXOXl5Sk5ObnW56EiBwAYgqta67WVlpamZcuW6Z133lFYWJjtundERIRCQkIUERGhUaNGacKECYqMjFR4eLjGjh2r5OTkWs9Yl0jkAAC4xbx58yRJffr0sRtftGiR7rnnHknS7NmzFRAQoGHDhqmyslIDBgzQ3LlzHToPiRwAYAz1XJJbrdbf3CY4OFiZmZnKzMysY1AkcgCAQfjr28+Y7AYAgA+jIgcAGIOTrzH10oKcRA4AMIb6nrVeX2itAwDgw6jIAQDG4KclOYkcAGAI/jprnUQOADAEk5OT3ZyaKOdGXCMHAMCHUZEDAAzBTy+Rk8gBAAbhp5mc1joAAD6MihwAYAjMWgcAwIcxax0AAHgdKnIAgCH46Vw3EjkAwCD8NJPTWgcAwIdRkQMADIFZ6wAA+DB/nbVOIgcAGIKfXiLnGjkAAL6MitxHvPbWNmW9vV15R09KkpJax2jiqFuU8rurPRwZXOHT/zukhSs368sDP+j4TyV6eeY9SunZwbbearXqpcUbteq9XSopO6Nrr07Q9IeG6oqWzT0YNRy1Y9te7dj+uU6dLJEkRcc0U8otyUq6OkGSVF19VutXb9bnObk6e7ZGV7W7QrfdfrPCwht7Mmz/4aclORW5j4iNaqKpY25V9uJJ+mDxJPXqdpX+MmmBvv72mKdDgwucqahSUutYTRt720XXv7riIy1dvV0zHhqmlS8/qJDgII2evECVVdX1HCmcEdEkTANv7aUHJ43Qg5OGq81V8Vq8YI0Kjp2QJK17e7P27/tWI+4dpPsfukMlxWVa8upaD0ftP0wu+OONPJrIMzIy1L17d4WFhSkqKkpDhgxRbm6uJ0PyWrf06qh+Pa/WlfFRahMfpcceGKTGjczave87T4cGF+h9XTuNu3eg+t3Q8YJ1VqtVS97epvuHp+jmnh2U2DpWzzx6p378qUQffLzPA9Girtp3vFLtrm6t5lFN1TwqUrcMukFB5iDlfXdMZ85U6tMdX+iPt/VRm8R4tYyP1u3DB+j7w0f1/eGjng4dXsyjiXzLli1KS0vTzp07tWnTJlVXV6t///4qLy/3ZFher6bGorf/naPTZ6rUvcMVng4Hbnbk2EkdP1mq313b1jYWFhqiTu3itfer7z0YGZxhsVi0N+drVVVVq9UVsfohr1A1NRa1TYy3bRMV00xNmobp+8N03lzh/Kx1ZxZv5NFr5Bs2bLD7nJWVpaioKOXk5Kh3794eisp7fXXwqAaOfl4VVWfVOMSsxc+MVmLrFp4OC252/FSpJKlZ0zC78cuahOrEyVJPhAQnHDt6XJnP/0tnz55VkDlId4++VdEtmunoDz8qsEGgQhoF220fFtZYZaUUN67gp5fIvWuyW3FxsSQpMjLyousrKytVWVlp+1xSUlIvcXmLNq2i9NHSySopO6N1H+5V+qzXtXbegyRzwIc0j4rUuMl/UcWZKn2x9xutfH2D7n/wDk+HBR/mNZPdLBaLxo0bp549e6pDhw4X3SYjI0MRERG2JS4urp6j9Kyghg3UOq65urSL19S0W3V121i9smKLp8OCmzX/uRL/6ZR99X2iqEyXRYZdbBd4sQYNAnVZ86ZqGR+tgbf2UovY5tq+ZY/Cwhqr5myNzpyusNu+tLRcoWHMWncJkwsWL+Q1iTwtLU379u3T8uXLL7nNlClTVFxcbFvy8/PrMULvY7FYVVXNrGV/17JFpJpHhmnHZwdsY2XlFfq//Xnq0r6VByODK1itVp2trtHl8dEKDAzQwW/ybOt+LDypolOlapVA180V/HXWule01tPT07V+/Xpt3bpVLVu2vOR2ZrNZZrO5HiPzHo9nrtXNv2uvltFNVXa6Um9t3K2P9xzUqhfHeDo0uED5mUrl/XDC9vnIsZPaf/AHRYQ1Umx0U909tJfmv5GtKy5vrstjIjUna4OimoXb3WsO7/f+2m1KbJ+gJk3DVFlZpb27v9a3B/M1aswwhYSY1T25o9a9vVkhjYIVHGzWO29mq1VCC7VKiPV06PBiHk3kVqtVY8eO1erVq7V582YlJCR4MhyvduJUqdJmLlXhiRKFhwarfZtYrXpxjPr0SPJ0aHCBfbn5Sp043/b56fnn7h0e0r+bnn7kTo2+o6/OVFRp2uw3VVJ2Rl07JGjB0/fJHNTQUyGjDspKT2vF0vdVUlKu4OAgtYhtrlFjhumqpCskSYOG9pHJJC1duE5nz55VYtIVuu2OFM8G7Uf89VnrJqvVavXUyceMGaNly5bpnXfeUWJiom08IiJCISEhv7l/SUmJIiIidPR4kcLDw90ZKrzAidLK394IfmPtfm65MoIz5aV69JbOKi4udtvv8fO5IuebYwoNq/s5ykpL1PWqFm6NtS48eo183rx5Ki4uVp8+fdSiRQvbsmLFCk+GBQDwR3462c3jrXUAAFB3XjHZDQAAd3N25jmz1gEA8CRnH7PqnXnce+4jBwAAjqMiBwAYAs9aBwDAl/lpJqe1DgCAD6MiBwAYgr/OWqciBwAYwvlHtDqzOGLr1q0aNGiQYmNjZTKZtGbNGrv1VqtV06ZNU4sWLRQSEqKUlBQdOHDg4gf7FSRyAADcoLy8XJ07d1ZmZuZF1z/77LOaM2eO5s+fr127dqlx48YaMGCAKioqLrr9pdBaBwAYQn3PdRs4cKAGDhx40XVWq1UvvPCC/va3v2nw4MGSpCVLlig6Olpr1qzRnXfeWevzUJEDAIzBi561fvjwYRUUFCgl5T9vt4uIiFCPHj20Y8cOh45FRQ4AMARXTXYrKSmxGzebzTKbzQ4dq6CgQJIUHR1tNx4dHW1bV1tU5AAAOCAuLk4RERG2JSMjw6PxUJEDAAzBJOeetX5+1/z8fLv3kTtajUtSTEyMJKmwsFAtWrSwjRcWFqpLly4OHYuKHABgCK66RB4eHm631CWRJyQkKCYmRtnZ2baxkpIS7dq1S8nJyQ4di4ocAAA3KCsr08GDB22fDx8+rL179yoyMlLx8fEaN26cnnjiCbVt21YJCQmaOnWqYmNjNWTIEIfOQyIHABhCXR7q8sv9HbF792717dvX9nnChAmSpNTUVGVlZemRRx5ReXm5/vrXv6qoqEg33HCDNmzYoODgYIfOQyIHABhE/d5J3qdPH1mt1ksfzWTSrFmzNGvWLCdi4ho5AAA+jYocAGAI9d1ary8kcgCAIfjp68hprQMA4MuoyAEAhkBrHQAAH+aqZ617GxI5AMAY/PQiOdfIAQDwYVTkAABD8NOCnEQOADAGf53sRmsdAAAfRkUOADAEZq0DAODL/PQiOa11AAB8GBU5AMAQ/LQgJ5EDAIyBWesAAMDrUJEDAAzCuVnr3tpcJ5EDAAyB1joAAPA6JHIAAHwYrXUAgCH4a2udRA4AMAR/fUQrrXUAAHwYFTkAwBBorQMA4MP89RGttNYBAPBhVOQAAGPw05KcRA4AMARmrQMAAK9DRQ4AMARmrQMA4MP89BI5iRwAYBB+msm5Rg4AgA+jIgcAGIK/zlonkQMADIHJbl7IarVKkkpLSzwcCepDaVmlp0NAPTpTXurpEFAPKsrLJP3n97k7lZQ4lyuc3d9dfDqRl5ae+x89sXW8hyMBADijtLRUERERbjl2UFCQYmJi1DYhzuljxcTEKCgoyAVRuY7JWh9fg9zEYrHo6NGjCgsLk8lbex5uUFJSori4OOXn5ys8PNzT4cCN+Ls2DqP+XVutVpWWlio2NlYBAe6bf11RUaGqqiqnjxMUFKTg4GAXROQ6Pl2RBwQEqGXLlp4Ow2PCw8MN9T+8kfF3bRxG/Lt2VyX+34KDg70uAbsKt58BAODDSOQAAPgwErkPMpvNmj59usxms6dDgZvxd20c/F2jrnx6shsAAEZHRQ4AgA8jkQMA4MNI5AAA+DASuY/JzMzUFVdcoeDgYPXo0UP/+7//6+mQ4AZbt27VoEGDFBsbK5PJpDVr1ng6JLhJRkaGunfvrrCwMEVFRWnIkCHKzc31dFjwISRyH7JixQpNmDBB06dP1549e9S5c2cNGDBAP/74o6dDg4uVl5erc+fOyszM9HQocLMtW7YoLS1NO3fu1KZNm1RdXa3+/furvLzc06HBRzBr3Yf06NFD3bt318svvyzp3CNq4+LiNHbsWE2ePNnD0cFdTCaTVq9erSFDhng6FNSD48ePKyoqSlu2bFHv3r09HQ58ABW5j6iqqlJOTo5SUlJsYwEBAUpJSdGOHTs8GBkAVyouLpYkRUZGejgS+AoSuY84ceKEampqFB0dbTceHR2tgoICD0UFwJUsFovGjRunnj17qkOHDp4OBz7Cp1+aAgD+JC0tTfv27dP27ds9HQp8CIncR1x22WUKDAxUYWGh3XhhYaFiYmI8FBUAV0lPT9f69eu1detWQ7/VEY6jte4jgoKC1LVrV2VnZ9vGLBaLsrOzlZyc7MHIADjDarUqPT1dq1ev1ocffqiEhARPhwQfQ0XuQyZMmKDU1FR169ZN1113nV544QWVl5dr5MiRng4NLlZWVqaDBw/aPh8+fFh79+5VZGSk4uPjPRgZXC0tLU3Lli3TO++8o7CwMNucl4iICIWEhHg4OvgCbj/zMS+//LKee+45FRQUqEuXLpozZ4569Ojh6bDgYps3b1bfvn0vGE9NTVVWVlb9BwS3MZlMFx1ftGiR7rnnnvoNBj6JRA4AgA/jGjkAAD6MRA4AgA8jkQMA4MNI5AAA+DASOQAAPoxEDgCADyORAwDgw0jkAAD4MBI54KR77rlHQ4YMsX3u06ePxo0bV+9xbN68WSaTSUVFRZfcxmQyac2aNbU+5owZM9SlSxen4vruu+9kMpm0d+9ep44D4OJI5PBL99xzj0wmk0wmk4KCgtSmTRvNmjVLZ8+edfu53377bT3++OO12rY2yRcAfg0vTYHfuuWWW7Ro0SJVVlbqvffeU1pamho2bKgpU6ZcsG1VVZWCgoJcct7IyEiXHAcAaoOKHH7LbDYrJiZGrVq10gMPPKCUlBStXbtW0n/a4U8++aRiY2OVmJgoScrPz9ftt9+uJk2aKDIyUoMHD9Z3331nO2ZNTY0mTJigJk2aqFmzZnrkkUf0y9cV/LK1XllZqUcffVRxcXEym81q06aNFi5cqO+++872YpSmTZvKZDLZXpJhsViUkZGhhIQEhYSEqHPnznrzzTftzvPee+/pqquuUkhIiPr27WsXZ209+uijuuqqq9SoUSO1bt1aU6dOVXV19QXbvfLKK4qLi1OjRo10++23q7i42G79q6++qnbt2ik4OFhJSUmaO3euw7EAqBsSOQwjJCREVVVVts/Z2dnKzc3Vpk2btH79elVXV2vAgAEKCwvTtm3b9PHHHys0NFS33HKLbb/nn39eWVlZeu2117R9+3adPHlSq1ev/tXz3n333frXv/6lOXPmaP/+/XrllVcUGhqquLg4vfXWW5Kk3NxcHTt2TC+++KIkKSMjQ0uWLNH8+fP15Zdfavz48RoxYoS2bNki6dwXjqFDh2rQoEHau3evRo8ercmTJzv87yQsLExZWVn66quv9OKLL2rBggWaPXu23TYHDx7UypUrtW7dOm3YsEGfffaZxowZY1v/xhtvaNq0aXryySe1f/9+PfXUU5o6daoWL17scDwA6sAK+KHU1FTr4MGDrVar1WqxWKybNm2yms1m68SJE23ro6OjrZWVlbZ9li5dak1MTLRaLBbbWGVlpTUkJMS6ceNGq9VqtbZo0cL67LPP2tZXV1dbW7ZsaTuX1Wq13njjjdaHHnrIarVarbm5uVZJ1k2bNl00zo8++sgqyXrq1CnbWEVFhbVRo0bWTz75xG7bUaNGWe+66y6r1Wq1Tpkyxdq+fXu79Y8++ugFx/olSdbVq1dfcv1zzz1n7dq1q+3z9OnTrYGBgdYjR47Yxt5//31rQECA9dixY1ar1Wq98sorrcuWLbM7zuOPP25NTk62Wq1W6+HDh62SrJ999tklzwug7rhGDr+1fv16hYaGqrq6WhaLRX/+8581Y8YM2/qOHTvaXRf//PPPdfDgQYWFhdkdp6KiQocOHVJxcbGOHTtm9/73Bg0aqFu3bhe018/bu3evAgMDdeONN9Y67oMHD+r06dPq16+f3XhVVZWuueYaSdL+/fsveA99cnJyrc9x3ooVKzRnzhwdOnRIZWVlOnv2rMLDw+22iY+P1+WXX253HovFotzcXIWFhenQoUMaNWqU7rvvPts2Z8+eVUREhMPxAHAciRx+q2/fvpo3b56CgoIUGxurBg3s/3Nv3Lix3eeysjJ17dpVb7zxxgXHat68eZ1iCAkJcXifsrIySdK7775rl0Clc9f9XWXHjh0aPny4Zs6cqQEDBigiIkLLly/X888/73CsCxYsuOCLRWBgoMtiBXBpJHL4rcaNG6tNmza13v7aa6/VihUrFBUVdUFVel6LFi20a9cu9e7dW9K5yjMnJ0fXXnvtRbfv2LGjLBaLtmzZopSUlAvWn+8I1NTU2Mbat28vs9msvLy8S1by7dq1s03cO2/nzp2//UP+l08++UStWrXSY489Zhv7/vvvL9guLy9PR48eVWxsrO08AQEBSkxMVHR0tGJjY/Xtt99q+PDhDp0fgGsw2Q342fDhw3XZZZdp8ODB2rZtmw4fPqzNmzfrwQcf1JEjRyRJDz30kJ5++mmtWbNGX3/9tcaMGfOr94BfccUVSk1N1b333qs1a9bYjrly5UpJUqtWrWQymbR+/XodP35cZWVlCgsL08SJEzV+/HgtXrxYhw4d0p49e/TSSy/ZJpDdf//9OnDggCZNmqTc3FwtW7ZMWVlZDv28bdu2VV5enpYvX65Dhw5pzpw5F524FxwcrNTUVH3++efatm2bHnzwQd1+++2KiYmRJM2cOVMZGRmaM2eOvvnmG33xxRdatGiR/vGPfzgUD4C6IZEDP2vUqJG2bt2q+Ph4DR06VO3atdOoUaNUUVFhq9Affvhh/eUvf1FqaqqSk5MVFham22677VePO2/ePP3P//yPxowZo6SkJN13330qLy+XJF1++eWaOXOmJk+erOjoaKWnp0uSHn/8cU2dOlUZGRlq166dbrnlFr377rtKSEiQdO669VtvvaU1a9aoc+fOmj9/vp566imHft5bb71V48ePV3p6urp06aJPPvlEU6dOvWC7Nm3aaOjQofr973+v/v37q1OnTna3l40ePVqvvvqqFi1apI4dO+rGG29UVlaWLVYA7mWyXmqWDgAA8HpU5AAA+DASOQAAPoxEDgCADyORAwDgw0jkAAD4MBI5AAA+jEQOAIAPI5EDAODDSOQAAPgwEjkAAD6MRA4AgA8jkQMA4MP+f3peE+bBWDyLAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "evaluate_grouped(model_lstm, X_text_test, X_num_test, group_keys_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vx1jkJ9tfCUi"
      },
      "outputs": [],
      "source": [
        "# model_lstm.save(\"/content/drive/MyDrive/Thesis/Final Project/main/model_scenario_2/model_lstm.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4rGblFAXoHv"
      },
      "source": [
        "---\n",
        "### **BI-LSTM (4 FEATURES)**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JlXHLt5rA0--",
        "outputId": "87e97436-0724-4a96-b72b-81d99b4ebe5b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ text_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,089,000</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">186,880</span> │ embedding_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ numeric_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer_4   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │ numeric_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">131</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_layer_… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">131</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,448</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ text_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m1,089,000\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m186,880\u001b[0m │ embedding_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ numeric_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer_4   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m129\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │         \u001b[38;5;34m12\u001b[0m │ numeric_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m131\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ attention_layer_… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m131\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,448\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m195\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,284,920</span> (4.90 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,284,920\u001b[0m (4.90 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,284,786</span> (4.90 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,284,786\u001b[0m (4.90 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134</span> (536.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m134\u001b[0m (536.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 128ms/step - accuracy: 0.3400 - loss: 1.5765 - val_accuracy: 0.4162 - val_loss: 1.1769\n",
            "Epoch 2/100\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 112ms/step - accuracy: 0.3250 - loss: 1.3778 - val_accuracy: 0.4324 - val_loss: 1.1680\n",
            "Epoch 3/100\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 92ms/step - accuracy: 0.3941 - loss: 1.2743 - val_accuracy: 0.4216 - val_loss: 1.1553\n",
            "Epoch 4/100\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 117ms/step - accuracy: 0.4286 - loss: 1.2165 - val_accuracy: 0.4541 - val_loss: 1.1197\n",
            "Epoch 5/100\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 117ms/step - accuracy: 0.4471 - loss: 1.1716 - val_accuracy: 0.4865 - val_loss: 1.0579\n",
            "Epoch 6/100\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 134ms/step - accuracy: 0.5139 - loss: 1.0340 - val_accuracy: 0.6000 - val_loss: 0.9398\n",
            "Epoch 7/100\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 116ms/step - accuracy: 0.6194 - loss: 0.8836 - val_accuracy: 0.6270 - val_loss: 0.8818\n",
            "Epoch 8/100\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.6691 - loss: 0.7961 - val_accuracy: 0.6595 - val_loss: 0.8629\n",
            "Epoch 9/100\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 141ms/step - accuracy: 0.7152 - loss: 0.6749 - val_accuracy: 0.7405 - val_loss: 0.7935\n",
            "Epoch 10/100\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 107ms/step - accuracy: 0.8040 - loss: 0.5147 - val_accuracy: 0.7243 - val_loss: 0.7694\n",
            "Epoch 11/100\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.8367 - loss: 0.4639 - val_accuracy: 0.7351 - val_loss: 0.7851\n",
            "Epoch 12/100\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - accuracy: 0.8854 - loss: 0.3760 - val_accuracy: 0.7189 - val_loss: 0.8457\n",
            "Epoch 13/100\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 80ms/step - accuracy: 0.8947 - loss: 0.3541 - val_accuracy: 0.7189 - val_loss: 0.8987\n",
            "Epoch 14/100\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 139ms/step - accuracy: 0.9014 - loss: 0.3240 - val_accuracy: 0.7135 - val_loss: 0.8796\n",
            "Epoch 15/100\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 99ms/step - accuracy: 0.9336 - loss: 0.2493 - val_accuracy: 0.7189 - val_loss: 0.8494\n",
            "Epoch 16/100\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 84ms/step - accuracy: 0.9463 - loss: 0.2238 - val_accuracy: 0.7297 - val_loss: 0.9006\n",
            "Epoch 17/100\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 113ms/step - accuracy: 0.9447 - loss: 0.2195 - val_accuracy: 0.7351 - val_loss: 0.9431\n",
            "Epoch 18/100\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 105ms/step - accuracy: 0.9545 - loss: 0.1864 - val_accuracy: 0.7027 - val_loss: 0.9987\n",
            "Epoch 19/100\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 140ms/step - accuracy: 0.9577 - loss: 0.2100 - val_accuracy: 0.7351 - val_loss: 1.0334\n",
            "Epoch 20/100\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 107ms/step - accuracy: 0.9618 - loss: 0.1818 - val_accuracy: 0.6865 - val_loss: 1.1521\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Concatenate, Input, Embedding, LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "\n",
        "# Jumlah fitur numerik kamu\n",
        "NUM_NUMERIC_FEATURES = train_df[['is_dialogue_scaled', 'is_subject_scaled', 'count_lexicon_scaled']].shape[1]\n",
        "\n",
        "# --- TEXT INPUT BRANCH ---\n",
        "text_input = Input(shape=(MAX_LEN,), name=\"text_input\")\n",
        "x_text = Embedding(\n",
        "    input_dim=num_words,\n",
        "    output_dim=EMBEDDING_DIM,\n",
        "    weights=[embedding_matrix],\n",
        "    input_length=MAX_LEN,\n",
        "    trainable=True\n",
        ")(text_input)\n",
        "\n",
        "x_text = Bidirectional(LSTM(\n",
        "    64,\n",
        "    return_sequences=True,\n",
        "    dropout=0.4,\n",
        "    recurrent_dropout=0.4,\n",
        "))(x_text)\n",
        "x_text = AttentionLayer()(x_text)\n",
        "\n",
        "# --- NUMERIC INPUT BRANCH ---\n",
        "numeric_input = Input(shape=(NUM_NUMERIC_FEATURES,), name=\"numeric_input\")\n",
        "\n",
        "# Optional: normalization/dense layer\n",
        "x_numeric = BatchNormalization()(numeric_input)\n",
        "\n",
        "# --- CONCATENATE BOTH ---\n",
        "x = Concatenate()([x_text, x_numeric])\n",
        "\n",
        "# Fully connected layers\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# Output\n",
        "output = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Build model\n",
        "model_bilstm = Model(inputs=[text_input, numeric_input], outputs=output)\n",
        "model_bilstm.compile(\n",
        "    optimizer=Adam(learning_rate=2e-4),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_bilstm.summary()\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "\n",
        "history_bilstm = model_bilstm.fit(\n",
        "    {\"text_input\": X_text_train, \"numeric_input\": X_num_train},\n",
        "    y_train,\n",
        "    validation_split=0.1,\n",
        "    shuffle=True,  # penting\n",
        "    epochs=100,\n",
        "    batch_size=16,\n",
        "    callbacks = [early_stopping],\n",
        "    class_weight=class_weights_dict\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "id": "MEOuPu_pj4_4",
        "outputId": "9b602e8d-925e-4680-b54f-596263fdffa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9091    0.6667    0.7692        30\n",
            "           1     0.8462    0.7857    0.8148        84\n",
            "           2     0.6316    0.8372    0.7200        43\n",
            "\n",
            "    accuracy                         0.7771       157\n",
            "   macro avg     0.7956    0.7632    0.7680       157\n",
            "weighted avg     0.7994    0.7771    0.7801       157\n",
            "\n",
            "Precision: 0.7956\n",
            "Recall:    0.7632\n",
            "F1-score:  0.7680\n",
            "Accuracy:  0.7771\n",
            "Confusion Matrix:\n",
            " [[20  5  5]\n",
            " [ 2 66 16]\n",
            " [ 0  7 36]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "evaluate_grouped(model_bilstm, X_text_test, X_num_test, group_keys_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nESJ5hP1faZZ"
      },
      "outputs": [],
      "source": [
        "# model_bilstm.save(\"/content/drive/MyDrive/Thesis/Final Project/main/model_scenario_2/model_bilstm.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo0_uwtNXrIF"
      },
      "source": [
        "---\n",
        "### **GRU (4 FEATURE)**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u8_VTLkIXqty",
        "outputId": "079c28d3-5303-4fcc-e5d8-c8dc2bdb7657"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ text_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m1,089,000\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m70,272\u001b[0m │ embedding_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ numeric_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer_5   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m65\u001b[0m │ gru_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │         \u001b[38;5;34m12\u001b[0m │ numeric_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ attention_layer_… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ concatenate_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,352\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m195\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ text_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,089,000</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">70,272</span> │ embedding_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ numeric_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer_5   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ gru_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │ numeric_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_layer_… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,164,152\u001b[0m (4.44 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,164,152</span> (4.44 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,164,018\u001b[0m (4.44 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,164,018</span> (4.44 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m134\u001b[0m (536.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134</span> (536.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.3233 - loss: 1.6311 - val_accuracy: 0.2649 - val_loss: 1.1704\n",
            "Epoch 2/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.3282 - loss: 1.5111 - val_accuracy: 0.3189 - val_loss: 1.1681\n",
            "Epoch 3/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - accuracy: 0.3432 - loss: 1.4879 - val_accuracy: 0.3243 - val_loss: 1.1663\n",
            "Epoch 4/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - accuracy: 0.3445 - loss: 1.4442 - val_accuracy: 0.3459 - val_loss: 1.1648\n",
            "Epoch 5/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.3481 - loss: 1.4286 - val_accuracy: 0.3622 - val_loss: 1.1643\n",
            "Epoch 6/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.3766 - loss: 1.3606 - val_accuracy: 0.3568 - val_loss: 1.1626\n",
            "Epoch 7/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - accuracy: 0.3222 - loss: 1.4200 - val_accuracy: 0.3514 - val_loss: 1.1608\n",
            "Epoch 8/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.3652 - loss: 1.3850 - val_accuracy: 0.3568 - val_loss: 1.1581\n",
            "Epoch 9/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.3838 - loss: 1.3500 - val_accuracy: 0.3784 - val_loss: 1.1540\n",
            "Epoch 10/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 107ms/step - accuracy: 0.3860 - loss: 1.3676 - val_accuracy: 0.3784 - val_loss: 1.1456\n",
            "Epoch 11/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - accuracy: 0.4024 - loss: 1.3033 - val_accuracy: 0.4108 - val_loss: 1.1335\n",
            "Epoch 12/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - accuracy: 0.4507 - loss: 1.2693 - val_accuracy: 0.4162 - val_loss: 1.1175\n",
            "Epoch 13/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - accuracy: 0.4100 - loss: 1.2618 - val_accuracy: 0.4649 - val_loss: 1.0989\n",
            "Epoch 14/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.4501 - loss: 1.2269 - val_accuracy: 0.4973 - val_loss: 1.0730\n",
            "Epoch 15/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 98ms/step - accuracy: 0.4672 - loss: 1.1996 - val_accuracy: 0.5243 - val_loss: 1.0403\n",
            "Epoch 16/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.5169 - loss: 1.1151 - val_accuracy: 0.5568 - val_loss: 1.0139\n",
            "Epoch 17/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 107ms/step - accuracy: 0.5471 - loss: 1.0413 - val_accuracy: 0.5838 - val_loss: 0.9741\n",
            "Epoch 18/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - accuracy: 0.5554 - loss: 1.0425 - val_accuracy: 0.5892 - val_loss: 0.9392\n",
            "Epoch 19/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.6066 - loss: 0.9788 - val_accuracy: 0.6216 - val_loss: 0.9030\n",
            "Epoch 20/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - accuracy: 0.6242 - loss: 0.9063 - val_accuracy: 0.6649 - val_loss: 0.8605\n",
            "Epoch 21/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - accuracy: 0.6563 - loss: 0.8573 - val_accuracy: 0.6703 - val_loss: 0.8288\n",
            "Epoch 22/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.7036 - loss: 0.7478 - val_accuracy: 0.6757 - val_loss: 0.8021\n",
            "Epoch 23/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 97ms/step - accuracy: 0.7338 - loss: 0.6862 - val_accuracy: 0.6919 - val_loss: 0.7811\n",
            "Epoch 24/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.7543 - loss: 0.6733 - val_accuracy: 0.7027 - val_loss: 0.7508\n",
            "Epoch 25/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.7606 - loss: 0.6055 - val_accuracy: 0.7135 - val_loss: 0.7442\n",
            "Epoch 26/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 98ms/step - accuracy: 0.7861 - loss: 0.6002 - val_accuracy: 0.7081 - val_loss: 0.7443\n",
            "Epoch 27/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 106ms/step - accuracy: 0.8009 - loss: 0.5453 - val_accuracy: 0.7297 - val_loss: 0.7458\n",
            "Epoch 28/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.8410 - loss: 0.4741 - val_accuracy: 0.7351 - val_loss: 0.7397\n",
            "Epoch 29/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 95ms/step - accuracy: 0.8492 - loss: 0.4636 - val_accuracy: 0.7243 - val_loss: 0.7260\n",
            "Epoch 30/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.8541 - loss: 0.4399 - val_accuracy: 0.7351 - val_loss: 0.7269\n",
            "Epoch 31/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.8742 - loss: 0.4025 - val_accuracy: 0.7135 - val_loss: 0.7341\n",
            "Epoch 32/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 96ms/step - accuracy: 0.8932 - loss: 0.3772 - val_accuracy: 0.7081 - val_loss: 0.7813\n",
            "Epoch 33/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.8983 - loss: 0.3526 - val_accuracy: 0.7243 - val_loss: 0.7472\n",
            "Epoch 34/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.8956 - loss: 0.3361 - val_accuracy: 0.7135 - val_loss: 0.7452\n",
            "Epoch 35/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.9017 - loss: 0.3237 - val_accuracy: 0.7189 - val_loss: 0.7333\n",
            "Epoch 36/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - accuracy: 0.9060 - loss: 0.3147 - val_accuracy: 0.7081 - val_loss: 0.7283\n",
            "Epoch 37/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.9246 - loss: 0.2876 - val_accuracy: 0.7081 - val_loss: 0.7288\n",
            "Epoch 38/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.9222 - loss: 0.2716 - val_accuracy: 0.7135 - val_loss: 0.7618\n",
            "Epoch 39/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.9385 - loss: 0.2561 - val_accuracy: 0.7027 - val_loss: 0.7437\n",
            "done\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Concatenate, Input, Embedding, LSTM, Dense, Dropout, BatchNormalization, GRU\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "\n",
        "# Jumlah fitur numerik kamu\n",
        "# Jumlah fitur numerik kamu\n",
        "NUM_NUMERIC_FEATURES = train_df[['is_dialogue_scaled', 'is_subject_scaled', 'count_lexicon_scaled']].shape[1]\n",
        "\n",
        "# --- TEXT INPUT BRANCH ---\n",
        "text_input = Input(shape=(MAX_LEN,), name=\"text_input\")\n",
        "x_text = Embedding(\n",
        "    input_dim=num_words,\n",
        "    output_dim=EMBEDDING_DIM,\n",
        "    weights=[embedding_matrix],\n",
        "    input_length=MAX_LEN,\n",
        "    trainable=True\n",
        ")(text_input)\n",
        "\n",
        "x_text = GRU(\n",
        "    64,\n",
        "    return_sequences=True,\n",
        "    dropout=0.4,\n",
        "    recurrent_dropout=0.4,\n",
        ")(x_text)\n",
        "x_text = AttentionLayer()(x_text)\n",
        "\n",
        "# --- NUMERIC INPUT BRANCH ---\n",
        "numeric_input = Input(shape=(NUM_NUMERIC_FEATURES,), name=\"numeric_input\")\n",
        "\n",
        "# Optional: normalization/dense layer\n",
        "x_numeric = BatchNormalization()(numeric_input)\n",
        "\n",
        "# --- CONCATENATE BOTH ---\n",
        "x = Concatenate()([x_text, x_numeric])\n",
        "\n",
        "# Fully connected layers\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "# Output\n",
        "output = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Build model\n",
        "model_gru = Model(inputs=[text_input, numeric_input], outputs=output)\n",
        "model_gru.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_gru.summary()\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "\n",
        "history_gru = model_gru.fit(\n",
        "    {\"text_input\": X_text_train, \"numeric_input\": X_num_train},\n",
        "    y_train,\n",
        "    validation_split=0.1,\n",
        "    shuffle=True,  # penting\n",
        "    epochs=150,\n",
        "    batch_size=32,\n",
        "    callbacks = [early_stopping],\n",
        "    class_weight=class_weights_dict\n",
        ")\n",
        "\n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tc-codOMj8jf",
        "outputId": "36a5c8e4-947f-43b2-c823-cf17be893fb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8696    0.6667    0.7547        30\n",
            "           1     0.8472    0.7262    0.7821        84\n",
            "           2     0.5806    0.8372    0.6857        43\n",
            "\n",
            "    accuracy                         0.7452       157\n",
            "   macro avg     0.7658    0.7434    0.7408       157\n",
            "weighted avg     0.7785    0.7452    0.7504       157\n",
            "\n",
            "Precision: 0.7658\n",
            "Recall:    0.7434\n",
            "F1-score:  0.7408\n",
            "Accuracy:  0.7452\n"
          ]
        }
      ],
      "source": [
        "evaluate_grouped(model_gru, X_text_test, X_num_test, group_keys_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxIAIIHsfhVi"
      },
      "outputs": [],
      "source": [
        "# model_gru.save(\"/content/drive/MyDrive/Thesis/Final Project/main/model_scenario_2/model_gru.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJPd3BYgo5od"
      },
      "source": [
        "---\n",
        "## **3 FEATURE**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_NUMERIC_FEATURES = train_df[['is_subject_scaled','is_dialogue_scaled']].shape[1]\n"
      ],
      "metadata": {
        "id": "-j1pmR3XNyMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-99AUCQOAQX"
      },
      "source": [
        "---\n",
        "### **LSTM (3 FEATURES)**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6s7kEOe76oT6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fcad1171-b4d2-416a-ba48-86aeb9cd207d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_10\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_10\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ text_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_10        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m1,089,000\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m93,440\u001b[0m │ embedding_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ numeric_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer_10  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m65\u001b[0m │ lstm_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m8\u001b[0m │ numeric_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ attention_layer_… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_20          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ concatenate_10[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,288\u001b[0m │ dropout_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ dense_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_21          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m195\u001b[0m │ dropout_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ text_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_10        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,089,000</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">93,440</span> │ embedding_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ numeric_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer_10  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ lstm_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ numeric_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_layer_… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,288</span> │ dropout_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_21          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ dropout_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,187,252\u001b[0m (4.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,187,252</span> (4.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,187,120\u001b[0m (4.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,187,120</span> (4.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m132\u001b[0m (528.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> (528.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 124ms/step - accuracy: 0.3672 - loss: 1.6300 - val_accuracy: 0.3405 - val_loss: 1.1645\n",
            "Epoch 2/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.3652 - loss: 1.4650 - val_accuracy: 0.3568 - val_loss: 1.1644\n",
            "Epoch 3/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.3835 - loss: 1.4198 - val_accuracy: 0.3189 - val_loss: 1.1640\n",
            "Epoch 4/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 95ms/step - accuracy: 0.3693 - loss: 1.3341 - val_accuracy: 0.3189 - val_loss: 1.1634\n",
            "Epoch 5/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.3546 - loss: 1.2851 - val_accuracy: 0.3405 - val_loss: 1.1609\n",
            "Epoch 6/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.4038 - loss: 1.2304 - val_accuracy: 0.3730 - val_loss: 1.1574\n",
            "Epoch 7/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - accuracy: 0.3956 - loss: 1.2202 - val_accuracy: 0.4000 - val_loss: 1.1504\n",
            "Epoch 8/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.3994 - loss: 1.2040 - val_accuracy: 0.4378 - val_loss: 1.1420\n",
            "Epoch 9/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.3967 - loss: 1.2169 - val_accuracy: 0.4595 - val_loss: 1.1251\n",
            "Epoch 10/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.4206 - loss: 1.1726 - val_accuracy: 0.4595 - val_loss: 1.0994\n",
            "Epoch 11/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 0.4821 - loss: 1.1303 - val_accuracy: 0.5297 - val_loss: 1.0611\n",
            "Epoch 12/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - accuracy: 0.5278 - loss: 1.0573 - val_accuracy: 0.6000 - val_loss: 1.0123\n",
            "Epoch 13/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.5832 - loss: 0.9788 - val_accuracy: 0.6270 - val_loss: 0.9686\n",
            "Epoch 14/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.6013 - loss: 0.9263 - val_accuracy: 0.6595 - val_loss: 0.9153\n",
            "Epoch 15/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - accuracy: 0.6266 - loss: 0.8764 - val_accuracy: 0.6541 - val_loss: 0.8818\n",
            "Epoch 16/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.6959 - loss: 0.7888 - val_accuracy: 0.6649 - val_loss: 0.8472\n",
            "Epoch 17/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.7126 - loss: 0.7236 - val_accuracy: 0.6757 - val_loss: 0.8107\n",
            "Epoch 18/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.7597 - loss: 0.6474 - val_accuracy: 0.6811 - val_loss: 0.8094\n",
            "Epoch 19/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 102ms/step - accuracy: 0.7847 - loss: 0.6038 - val_accuracy: 0.6865 - val_loss: 0.8024\n",
            "Epoch 20/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 55ms/step - accuracy: 0.8049 - loss: 0.5402 - val_accuracy: 0.6811 - val_loss: 0.7980\n",
            "Epoch 21/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - accuracy: 0.8265 - loss: 0.5319 - val_accuracy: 0.7081 - val_loss: 0.7888\n",
            "Epoch 22/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.8322 - loss: 0.5085 - val_accuracy: 0.6973 - val_loss: 0.7995\n",
            "Epoch 23/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.8589 - loss: 0.4529 - val_accuracy: 0.6973 - val_loss: 0.7851\n",
            "Epoch 24/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.8622 - loss: 0.4084 - val_accuracy: 0.7189 - val_loss: 0.7787\n",
            "Epoch 25/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.8851 - loss: 0.3940 - val_accuracy: 0.7135 - val_loss: 0.7942\n",
            "Epoch 26/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 96ms/step - accuracy: 0.9052 - loss: 0.3314 - val_accuracy: 0.7189 - val_loss: 0.7975\n",
            "Epoch 27/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - accuracy: 0.8961 - loss: 0.3529 - val_accuracy: 0.7405 - val_loss: 0.7979\n",
            "Epoch 28/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.9086 - loss: 0.3124 - val_accuracy: 0.7243 - val_loss: 0.8079\n",
            "Epoch 29/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - accuracy: 0.9100 - loss: 0.3020 - val_accuracy: 0.7243 - val_loss: 0.8113\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Concatenate, Input, Embedding, LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "\n",
        "# Jumlah fitur numerik kamu\n",
        "\n",
        "# --- TEXT INPUT BRANCH ---\n",
        "text_input = Input(shape=(MAX_LEN,), name=\"text_input\")\n",
        "x_text = Embedding(\n",
        "    input_dim=num_words,\n",
        "    output_dim=EMBEDDING_DIM,\n",
        "    weights=[embedding_matrix],\n",
        "    input_length=MAX_LEN,\n",
        "    trainable=True\n",
        ")(text_input)\n",
        "\n",
        "x_text = LSTM(\n",
        "    64,\n",
        "    return_sequences=True,\n",
        "    dropout=0.4,\n",
        "    recurrent_dropout=0.4,\n",
        ")(x_text)\n",
        "x_text = AttentionLayer()(x_text)\n",
        "\n",
        "# --- NUMERIC INPUT BRANCH ---\n",
        "numeric_input = Input(shape=(NUM_NUMERIC_FEATURES,), name=\"numeric_input\")\n",
        "\n",
        "# Optional: normalization/dense layer\n",
        "x_numeric = BatchNormalization()(numeric_input)\n",
        "\n",
        "# --- CONCATENATE BOTH ---\n",
        "x = Concatenate()([x_text, x_numeric])\n",
        "\n",
        "# Fully connected layers\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# Output\n",
        "output = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Build model\n",
        "model_lstm_3 = Model(inputs=[text_input, numeric_input], outputs=output)\n",
        "model_lstm_3.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_lstm_3.summary()\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "\n",
        "history = model_lstm_3.fit(\n",
        "    {\"text_input\": X_text_train, \"numeric_input\": X_num_train_3},\n",
        "    y_train,\n",
        "    validation_split=0.1,\n",
        "    shuffle=True,  # penting\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    callbacks = [early_stopping],\n",
        "    class_weight=class_weights_dict\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fmX2k9Bmcjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cc937da-7e79-49a4-c7e6-e04f8ce48ca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7586    0.7333    0.7458        30\n",
            "           1     0.7841    0.8214    0.8023        84\n",
            "           2     0.6750    0.6279    0.6506        43\n",
            "\n",
            "    accuracy                         0.7516       157\n",
            "   macro avg     0.7392    0.7276    0.7329       157\n",
            "weighted avg     0.7493    0.7516    0.7500       157\n",
            "\n",
            "Precision: 0.7392\n",
            "Recall:    0.7276\n",
            "F1-score:  0.7329\n",
            "Accuracy:  0.7516\n"
          ]
        }
      ],
      "source": [
        "evaluate_grouped(model_lstm_3, X_text_test, X_num_test_3, group_keys_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhSgWKMrlV-h"
      },
      "source": [
        "---\n",
        "### **BILSTM (3 FEATURES)**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFVPWD9elZmi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ae4a25c2-0f91-4652-d086-8fce7a6d55e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ text_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_11        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m1,089,000\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m186,880\u001b[0m │ embedding_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ numeric_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer_11  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m129\u001b[0m │ bidirectional_3[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m8\u001b[0m │ numeric_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m130\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ attention_layer_… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_22          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m130\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_11[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,384\u001b[0m │ dropout_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ dense_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m195\u001b[0m │ dropout_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ text_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_11        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,089,000</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">186,880</span> │ embedding_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ numeric_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer_11  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ bidirectional_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ numeric_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_layer_… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_22          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,384</span> │ dropout_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ dropout_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,284,852\u001b[0m (4.90 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,284,852</span> (4.90 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,284,720\u001b[0m (4.90 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,284,720</span> (4.90 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m132\u001b[0m (528.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> (528.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 192ms/step - accuracy: 0.3004 - loss: 1.7928 - val_accuracy: 0.4216 - val_loss: 1.1758\n",
            "Epoch 2/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 129ms/step - accuracy: 0.3547 - loss: 1.4062 - val_accuracy: 0.3730 - val_loss: 1.1711\n",
            "Epoch 3/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.3554 - loss: 1.3321 - val_accuracy: 0.3892 - val_loss: 1.1660\n",
            "Epoch 4/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.4054 - loss: 1.2123 - val_accuracy: 0.3676 - val_loss: 1.1573\n",
            "Epoch 5/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 93ms/step - accuracy: 0.4437 - loss: 1.2068 - val_accuracy: 0.3946 - val_loss: 1.1412\n",
            "Epoch 6/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.4709 - loss: 1.1555 - val_accuracy: 0.4703 - val_loss: 1.1110\n",
            "Epoch 7/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 92ms/step - accuracy: 0.5452 - loss: 1.0519 - val_accuracy: 0.5784 - val_loss: 1.0614\n",
            "Epoch 8/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.6073 - loss: 0.9536 - val_accuracy: 0.6000 - val_loss: 0.9994\n",
            "Epoch 9/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.6530 - loss: 0.8451 - val_accuracy: 0.6378 - val_loss: 0.9060\n",
            "Epoch 10/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.7151 - loss: 0.7489 - val_accuracy: 0.6919 - val_loss: 0.8272\n",
            "Epoch 11/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - accuracy: 0.7741 - loss: 0.6257 - val_accuracy: 0.6865 - val_loss: 0.8078\n",
            "Epoch 12/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.8297 - loss: 0.5200 - val_accuracy: 0.7135 - val_loss: 0.7733\n",
            "Epoch 13/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 163ms/step - accuracy: 0.8265 - loss: 0.4797 - val_accuracy: 0.7189 - val_loss: 0.8047\n",
            "Epoch 14/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - accuracy: 0.8627 - loss: 0.4350 - val_accuracy: 0.7189 - val_loss: 0.8062\n",
            "Epoch 15/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 117ms/step - accuracy: 0.8884 - loss: 0.3839 - val_accuracy: 0.7351 - val_loss: 0.8255\n",
            "Epoch 16/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.9162 - loss: 0.3184 - val_accuracy: 0.7297 - val_loss: 0.8303\n",
            "Epoch 17/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 96ms/step - accuracy: 0.9281 - loss: 0.2705 - val_accuracy: 0.7514 - val_loss: 0.8312\n",
            "Epoch 18/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 161ms/step - accuracy: 0.9380 - loss: 0.2504 - val_accuracy: 0.7351 - val_loss: 0.9026\n",
            "Epoch 19/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 93ms/step - accuracy: 0.9355 - loss: 0.2591 - val_accuracy: 0.7405 - val_loss: 0.8839\n",
            "Epoch 20/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 125ms/step - accuracy: 0.9456 - loss: 0.2316 - val_accuracy: 0.7351 - val_loss: 0.9255\n",
            "Epoch 21/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 95ms/step - accuracy: 0.9606 - loss: 0.2094 - val_accuracy: 0.7405 - val_loss: 0.9349\n",
            "Epoch 22/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 168ms/step - accuracy: 0.9725 - loss: 0.1815 - val_accuracy: 0.7243 - val_loss: 0.9689\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Concatenate, Input, Embedding, LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# --- TEXT INPUT BRANCH ---\n",
        "text_input = Input(shape=(MAX_LEN,), name=\"text_input\")\n",
        "x_text = Embedding(\n",
        "    input_dim=num_words,\n",
        "    output_dim=EMBEDDING_DIM,\n",
        "    weights=[embedding_matrix],\n",
        "    input_length=MAX_LEN,\n",
        "    trainable=True\n",
        ")(text_input)\n",
        "\n",
        "x_text = Bidirectional(LSTM(\n",
        "    64,\n",
        "    return_sequences=True,\n",
        "    dropout=0.4,\n",
        "    recurrent_dropout=0.4,\n",
        "))(x_text)\n",
        "x_text = AttentionLayer()(x_text)\n",
        "\n",
        "# --- NUMERIC INPUT BRANCH ---\n",
        "numeric_input = Input(shape=(NUM_NUMERIC_FEATURES,), name=\"numeric_input\")\n",
        "\n",
        "# Optional: normalization/dense layer\n",
        "x_numeric = BatchNormalization()(numeric_input)\n",
        "\n",
        "# --- CONCATENATE BOTH ---\n",
        "x = Concatenate()([x_text, x_numeric])\n",
        "\n",
        "# Fully connected layers\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# Output\n",
        "output = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Build model\n",
        "model_bilstm_3 = Model(inputs=[text_input, numeric_input], outputs=output)\n",
        "model_bilstm_3.compile(\n",
        "    optimizer=Adam(learning_rate=2e-4),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_bilstm_3.summary()\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "\n",
        "history_bilstm = model_bilstm_3.fit(\n",
        "    {\"text_input\": X_text_train, \"numeric_input\": X_num_train_3},\n",
        "    y_train,\n",
        "    validation_split=0.1,\n",
        "    shuffle=True,  # penting\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks = [early_stopping],\n",
        "    class_weight=class_weights_dict\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGBMT9zhmlJn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "602efa65-919b-4b53-fd2c-f213b4962466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8214    0.7667    0.7931        30\n",
            "           1     0.8395    0.8095    0.8242        84\n",
            "           2     0.6458    0.7209    0.6813        43\n",
            "\n",
            "    accuracy                         0.7771       157\n",
            "   macro avg     0.7689    0.7657    0.7662       157\n",
            "weighted avg     0.7830    0.7771    0.7791       157\n",
            "\n",
            "Precision: 0.7689\n",
            "Recall:    0.7657\n",
            "F1-score:  0.7662\n",
            "Accuracy:  0.7771\n"
          ]
        }
      ],
      "source": [
        "evaluate_grouped(model_bilstm_3, X_text_test, X_num_test_3, group_keys_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uIwZSabfnmt"
      },
      "outputs": [],
      "source": [
        "# model_bilstm_3.save(\"/content/drive/MyDrive/Thesis/Final Project/main/model_scenario_2/model_bilstm_3.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKsloya7lcme"
      },
      "source": [
        "---\n",
        "### **GRU (3 FEATURES)**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6y4qtWVlfTV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fdac424a-49ea-4904-d5be-2c16268b2fd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_12\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_12\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ text_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_12        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m1,089,000\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m70,272\u001b[0m │ embedding_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ numeric_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer_12  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m65\u001b[0m │ gru_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m8\u001b[0m │ numeric_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_12      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ attention_layer_… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_24          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ concatenate_12[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,288\u001b[0m │ dropout_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ dense_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_25          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m195\u001b[0m │ dropout_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ text_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_12        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,089,000</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">70,272</span> │ embedding_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ numeric_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer_12  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ gru_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ numeric_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_12      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_layer_… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_24          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,288</span> │ dropout_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_25          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ dropout_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,164,084\u001b[0m (4.44 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,164,084</span> (4.44 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,163,952\u001b[0m (4.44 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,163,952</span> (4.44 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m132\u001b[0m (528.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> (528.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 118ms/step - accuracy: 0.3754 - loss: 1.6478 - val_accuracy: 0.3784 - val_loss: 1.1644\n",
            "Epoch 2/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.3399 - loss: 1.5444 - val_accuracy: 0.3946 - val_loss: 1.1580\n",
            "Epoch 3/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.3607 - loss: 1.4029 - val_accuracy: 0.4162 - val_loss: 1.1511\n",
            "Epoch 4/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 77ms/step - accuracy: 0.3685 - loss: 1.3262 - val_accuracy: 0.4054 - val_loss: 1.1429\n",
            "Epoch 5/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.3553 - loss: 1.3058 - val_accuracy: 0.4595 - val_loss: 1.1321\n",
            "Epoch 6/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.3968 - loss: 1.2333 - val_accuracy: 0.4811 - val_loss: 1.1205\n",
            "Epoch 7/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step - accuracy: 0.4117 - loss: 1.2359 - val_accuracy: 0.4757 - val_loss: 1.1075\n",
            "Epoch 8/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - accuracy: 0.4298 - loss: 1.2130 - val_accuracy: 0.5027 - val_loss: 1.0920\n",
            "Epoch 9/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.4246 - loss: 1.2211 - val_accuracy: 0.5135 - val_loss: 1.0710\n",
            "Epoch 10/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 99ms/step - accuracy: 0.4587 - loss: 1.1441 - val_accuracy: 0.5459 - val_loss: 1.0461\n",
            "Epoch 11/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - accuracy: 0.4655 - loss: 1.1302 - val_accuracy: 0.5351 - val_loss: 1.0210\n",
            "Epoch 12/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 104ms/step - accuracy: 0.5110 - loss: 1.0831 - val_accuracy: 0.5730 - val_loss: 0.9861\n",
            "Epoch 13/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - accuracy: 0.4809 - loss: 1.0876 - val_accuracy: 0.6108 - val_loss: 0.9521\n",
            "Epoch 14/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5444 - loss: 1.0280 - val_accuracy: 0.6162 - val_loss: 0.9183\n",
            "Epoch 15/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 97ms/step - accuracy: 0.6020 - loss: 0.9354 - val_accuracy: 0.6324 - val_loss: 0.8846\n",
            "Epoch 16/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - accuracy: 0.6378 - loss: 0.8900 - val_accuracy: 0.6378 - val_loss: 0.8572\n",
            "Epoch 17/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.6269 - loss: 0.8504 - val_accuracy: 0.6595 - val_loss: 0.8231\n",
            "Epoch 18/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - accuracy: 0.6787 - loss: 0.7995 - val_accuracy: 0.6703 - val_loss: 0.8089\n",
            "Epoch 19/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.7126 - loss: 0.7211 - val_accuracy: 0.6973 - val_loss: 0.7835\n",
            "Epoch 20/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.7422 - loss: 0.6669 - val_accuracy: 0.7189 - val_loss: 0.7566\n",
            "Epoch 21/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 106ms/step - accuracy: 0.7920 - loss: 0.6023 - val_accuracy: 0.7027 - val_loss: 0.7392\n",
            "Epoch 22/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - accuracy: 0.7977 - loss: 0.5600 - val_accuracy: 0.7135 - val_loss: 0.7284\n",
            "Epoch 23/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.8306 - loss: 0.5248 - val_accuracy: 0.7297 - val_loss: 0.7262\n",
            "Epoch 24/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - accuracy: 0.8574 - loss: 0.4743 - val_accuracy: 0.7243 - val_loss: 0.7171\n",
            "Epoch 25/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.8472 - loss: 0.4649 - val_accuracy: 0.7189 - val_loss: 0.7169\n",
            "Epoch 26/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.8787 - loss: 0.4131 - val_accuracy: 0.7189 - val_loss: 0.7115\n",
            "Epoch 27/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - accuracy: 0.8864 - loss: 0.3711 - val_accuracy: 0.6973 - val_loss: 0.7317\n",
            "Epoch 28/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.9088 - loss: 0.3408 - val_accuracy: 0.7189 - val_loss: 0.7224\n",
            "Epoch 29/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.9131 - loss: 0.3229 - val_accuracy: 0.7243 - val_loss: 0.7256\n",
            "Epoch 30/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.9157 - loss: 0.3264 - val_accuracy: 0.7243 - val_loss: 0.7324\n",
            "Epoch 31/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 92ms/step - accuracy: 0.9239 - loss: 0.2908 - val_accuracy: 0.7243 - val_loss: 0.7362\n",
            "Epoch 32/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.9037 - loss: 0.3080 - val_accuracy: 0.7081 - val_loss: 0.7667\n",
            "Epoch 33/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.9152 - loss: 0.3035 - val_accuracy: 0.7351 - val_loss: 0.7564\n",
            "Epoch 34/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.9286 - loss: 0.2697 - val_accuracy: 0.7351 - val_loss: 0.7591\n",
            "Epoch 35/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.9397 - loss: 0.2479 - val_accuracy: 0.7351 - val_loss: 0.7733\n",
            "Epoch 36/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - accuracy: 0.9614 - loss: 0.2007 - val_accuracy: 0.7297 - val_loss: 0.7896\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Concatenate, Input, Embedding, LSTM, Dense, Dropout, BatchNormalization, GRU\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "\n",
        "\n",
        "# --- TEXT INPUT BRANCH ---\n",
        "text_input = Input(shape=(MAX_LEN,), name=\"text_input\")\n",
        "x_text = Embedding(\n",
        "    input_dim=num_words,\n",
        "    output_dim=EMBEDDING_DIM,\n",
        "    weights=[embedding_matrix],\n",
        "    input_length=MAX_LEN,\n",
        "    trainable=True\n",
        ")(text_input)\n",
        "\n",
        "x_text = GRU(\n",
        "    64,\n",
        "    return_sequences=True,\n",
        "    dropout=0.4,\n",
        "    recurrent_dropout=0.4,\n",
        ")(x_text)\n",
        "x_text = AttentionLayer()(x_text)\n",
        "\n",
        "# --- NUMERIC INPUT BRANCH ---\n",
        "numeric_input = Input(shape=(NUM_NUMERIC_FEATURES,), name=\"numeric_input\")\n",
        "\n",
        "# Optional: normalization/dense layer\n",
        "x_numeric = BatchNormalization()(numeric_input)\n",
        "\n",
        "# --- CONCATENATE BOTH ---\n",
        "x = Concatenate()([x_text, x_numeric])\n",
        "\n",
        "# Fully connected layers\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# Output\n",
        "output = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Build model\n",
        "model_gru_3 = Model(inputs=[text_input, numeric_input], outputs=output)\n",
        "model_gru_3.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_gru_3.summary()\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "\n",
        "history_gru = model_gru_3.fit(\n",
        "    {\"text_input\": X_text_train, \"numeric_input\": X_num_train_3},\n",
        "    y_train,\n",
        "    validation_split=0.1,\n",
        "    shuffle=True,  # penting\n",
        "    epochs=150,\n",
        "    batch_size=32,\n",
        "    callbacks = [early_stopping],\n",
        "    class_weight=class_weights_dict\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vI7mLU2rmplg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "03a7743d-76c0-4fdd-e028-82715427818b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9167    0.7333    0.8148        30\n",
            "           1     0.7692    0.8333    0.8000        84\n",
            "           2     0.6190    0.6047    0.6118        43\n",
            "\n",
            "    accuracy                         0.7516       157\n",
            "   macro avg     0.7683    0.7238    0.7422       157\n",
            "weighted avg     0.7563    0.7516    0.7513       157\n",
            "\n",
            "Precision: 0.7683\n",
            "Recall:    0.7238\n",
            "F1-score:  0.7422\n",
            "Accuracy:  0.7516\n",
            "Confusion Matrix:\n",
            " [[22  5  3]\n",
            " [ 1 70 13]\n",
            " [ 1 16 26]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "evaluate_grouped(model_gru_3, X_text_test, X_num_test_3, group_keys_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gHB_NJvy5WU"
      },
      "outputs": [],
      "source": [
        "# model_gru_3.save(\"/content/drive/MyDrive/Thesis/Final Project/main/model_scenario_2/model_gru_3.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auhYVraro7nH"
      },
      "source": [
        "---\n",
        "## **2 FEATURE**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_NUMERIC_FEATURES = train_df[['is_dialogue_scaled']].shape[1]\n"
      ],
      "metadata": {
        "id": "qLG4b70MN7z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKRjPvB2lkDc"
      },
      "source": [
        "---\n",
        "### **LSTM (2 FEATURES)**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eDdFg8RlxwI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af5400ed-161b-4ef8-e970-da647bb02371"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_17\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_17\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ text_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_17        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m1,089,000\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m93,440\u001b[0m │ embedding_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ numeric_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer_17  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m65\u001b[0m │ lstm_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m4\u001b[0m │ numeric_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_17      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ attention_layer_… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_34          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ concatenate_17[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,224\u001b[0m │ dropout_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ dense_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_35          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m195\u001b[0m │ dropout_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ text_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_17        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,089,000</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">93,440</span> │ embedding_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ numeric_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer_17  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ lstm_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │ numeric_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_17      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_layer_… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_34          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │ dropout_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_35          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ dropout_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,187,184\u001b[0m (4.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,187,184</span> (4.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,187,054\u001b[0m (4.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,187,054</span> (4.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m130\u001b[0m (520.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> (520.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - accuracy: 0.3226 - loss: 1.5507 - val_accuracy: 0.3081 - val_loss: 1.1645\n",
            "Epoch 2/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.3152 - loss: 1.4071 - val_accuracy: 0.3946 - val_loss: 1.1624\n",
            "Epoch 3/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.3528 - loss: 1.3034 - val_accuracy: 0.4378 - val_loss: 1.1586\n",
            "Epoch 4/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - accuracy: 0.3705 - loss: 1.2587 - val_accuracy: 0.4703 - val_loss: 1.1549\n",
            "Epoch 5/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.3734 - loss: 1.2627 - val_accuracy: 0.4541 - val_loss: 1.1498\n",
            "Epoch 6/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.3942 - loss: 1.2032 - val_accuracy: 0.4703 - val_loss: 1.1426\n",
            "Epoch 7/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.4296 - loss: 1.1739 - val_accuracy: 0.4973 - val_loss: 1.1303\n",
            "Epoch 8/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.4199 - loss: 1.1793 - val_accuracy: 0.5189 - val_loss: 1.1096\n",
            "Epoch 9/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.4394 - loss: 1.1402 - val_accuracy: 0.5405 - val_loss: 1.0851\n",
            "Epoch 10/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.4686 - loss: 1.1151 - val_accuracy: 0.5622 - val_loss: 1.0609\n",
            "Epoch 11/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.5392 - loss: 1.0131 - val_accuracy: 0.5838 - val_loss: 1.0230\n",
            "Epoch 12/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.5392 - loss: 1.0048 - val_accuracy: 0.6378 - val_loss: 0.9767\n",
            "Epoch 13/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 93ms/step - accuracy: 0.5784 - loss: 0.9537 - val_accuracy: 0.6216 - val_loss: 0.9476\n",
            "Epoch 14/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.6152 - loss: 0.8958 - val_accuracy: 0.6378 - val_loss: 0.9101\n",
            "Epoch 15/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.6281 - loss: 0.8616 - val_accuracy: 0.6378 - val_loss: 0.8806\n",
            "Epoch 16/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.6472 - loss: 0.8093 - val_accuracy: 0.6703 - val_loss: 0.8284\n",
            "Epoch 17/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - accuracy: 0.7105 - loss: 0.7317 - val_accuracy: 0.6865 - val_loss: 0.8106\n",
            "Epoch 18/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.7496 - loss: 0.6767 - val_accuracy: 0.6919 - val_loss: 0.8150\n",
            "Epoch 19/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.7725 - loss: 0.6168 - val_accuracy: 0.7081 - val_loss: 0.7760\n",
            "Epoch 20/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.8020 - loss: 0.5814 - val_accuracy: 0.7081 - val_loss: 0.7635\n",
            "Epoch 21/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - accuracy: 0.7763 - loss: 0.5708 - val_accuracy: 0.7081 - val_loss: 0.7565\n",
            "Epoch 22/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.8302 - loss: 0.5028 - val_accuracy: 0.7135 - val_loss: 0.7479\n",
            "Epoch 23/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 95ms/step - accuracy: 0.8343 - loss: 0.4771 - val_accuracy: 0.7243 - val_loss: 0.7514\n",
            "Epoch 24/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 116ms/step - accuracy: 0.8382 - loss: 0.4642 - val_accuracy: 0.6919 - val_loss: 0.8167\n",
            "Epoch 25/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.8696 - loss: 0.4003 - val_accuracy: 0.7243 - val_loss: 0.7775\n",
            "Epoch 26/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.8867 - loss: 0.3708 - val_accuracy: 0.7081 - val_loss: 0.7885\n",
            "Epoch 27/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.8833 - loss: 0.3851 - val_accuracy: 0.7135 - val_loss: 0.7979\n",
            "Epoch 28/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.9009 - loss: 0.3441 - val_accuracy: 0.7243 - val_loss: 0.7995\n",
            "Epoch 29/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - accuracy: 0.9240 - loss: 0.2831 - val_accuracy: 0.7189 - val_loss: 0.8050\n",
            "Epoch 30/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.9179 - loss: 0.3002 - val_accuracy: 0.7081 - val_loss: 0.8087\n",
            "Epoch 31/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9327 - loss: 0.2628 - val_accuracy: 0.7189 - val_loss: 0.8315\n",
            "Epoch 32/150\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9177 - loss: 0.2861 - val_accuracy: 0.7081 - val_loss: 0.8463\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Concatenate, Input, Embedding, LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "\n",
        "# --- TEXT INPUT BRANCH ---\n",
        "text_input = Input(shape=(MAX_LEN,), name=\"text_input\")\n",
        "x_text = Embedding(\n",
        "    input_dim=num_words,\n",
        "    output_dim=EMBEDDING_DIM,\n",
        "    weights=[embedding_matrix],\n",
        "    input_length=MAX_LEN,\n",
        "    trainable=True\n",
        ")(text_input)\n",
        "\n",
        "x_text = LSTM(\n",
        "    64,\n",
        "    return_sequences=True,\n",
        "    dropout=0.4,\n",
        "    recurrent_dropout=0.4,\n",
        ")(x_text)\n",
        "x_text = AttentionLayer()(x_text)\n",
        "\n",
        "# --- NUMERIC INPUT BRANCH ---\n",
        "numeric_input = Input(shape=(NUM_NUMERIC_FEATURES,), name=\"numeric_input\")\n",
        "\n",
        "# Optional: normalization/dense layer\n",
        "x_numeric = BatchNormalization()(numeric_input)\n",
        "\n",
        "# --- CONCATENATE BOTH ---\n",
        "x = Concatenate()([x_text, x_numeric])\n",
        "\n",
        "# Fully connected layers\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# Output\n",
        "output = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Build model\n",
        "model_lstm_2 = Model(inputs=[text_input, numeric_input], outputs=output)\n",
        "model_lstm_2.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_lstm_2.summary()\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "\n",
        "history = model_lstm_2.fit(\n",
        "    {\"text_input\": X_text_train, \"numeric_input\": X_num_train_2},\n",
        "    y_train,\n",
        "    validation_split=0.1,\n",
        "    shuffle=True,  # penting\n",
        "    epochs=150,\n",
        "    batch_size=32,\n",
        "    callbacks = [early_stopping],\n",
        "    class_weight=class_weights_dict\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Tlrl1JGm-xy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45191d50-face-418d-fd26-aa80285c9808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7333    0.7333    0.7333        30\n",
            "           1     0.7901    0.7619    0.7758        84\n",
            "           2     0.6087    0.6512    0.6292        43\n",
            "\n",
            "    accuracy                         0.7261       157\n",
            "   macro avg     0.7107    0.7155    0.7128       157\n",
            "weighted avg     0.7296    0.7261    0.7275       157\n",
            "\n",
            "Precision: 0.7107\n",
            "Recall:    0.7155\n",
            "F1-score:  0.7128\n",
            "Accuracy:  0.7261\n"
          ]
        }
      ],
      "source": [
        "evaluate_grouped(model_lstm_2, X_text_test, X_num_test_2, group_keys_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inbxQTxS28V0"
      },
      "outputs": [],
      "source": [
        "# model_lstm_2.save(\"/content/drive/MyDrive/Thesis/Final Project/main/model_scenario_2/model_lstm_2.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrXPqWUxlpJl"
      },
      "source": [
        "---\n",
        "### **BILSTM (2 FEATURES)**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "to-hNX9emB_7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "091d77a5-c91b-4b34-a82a-8d5d63470a59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_18\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_18\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ text_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_18        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m1,089,000\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m186,880\u001b[0m │ embedding_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ numeric_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer_18  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m129\u001b[0m │ bidirectional_5[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m4\u001b[0m │ numeric_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_18      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m129\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ attention_layer_… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_36          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m129\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_18[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,320\u001b[0m │ dropout_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ dense_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_37          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m195\u001b[0m │ dropout_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ text_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_18        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,089,000</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">186,880</span> │ embedding_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ numeric_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer_18  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ bidirectional_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │ numeric_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_18      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_layer_… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_36          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ dropout_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_37          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ dropout_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,284,784\u001b[0m (4.90 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,284,784</span> (4.90 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,284,654\u001b[0m (4.90 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,284,654</span> (4.90 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m130\u001b[0m (520.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> (520.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 233ms/step - accuracy: 0.3511 - loss: 1.5349 - val_accuracy: 0.3676 - val_loss: 1.1831\n",
            "Epoch 2/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 116ms/step - accuracy: 0.3521 - loss: 1.3524 - val_accuracy: 0.3730 - val_loss: 1.1820\n",
            "Epoch 3/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 96ms/step - accuracy: 0.3712 - loss: 1.2792 - val_accuracy: 0.3784 - val_loss: 1.1805\n",
            "Epoch 4/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 164ms/step - accuracy: 0.3784 - loss: 1.2831 - val_accuracy: 0.4378 - val_loss: 1.1764\n",
            "Epoch 5/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 95ms/step - accuracy: 0.4035 - loss: 1.2358 - val_accuracy: 0.4378 - val_loss: 1.1665\n",
            "Epoch 6/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 129ms/step - accuracy: 0.4097 - loss: 1.1931 - val_accuracy: 0.4919 - val_loss: 1.1581\n",
            "Epoch 7/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - accuracy: 0.4442 - loss: 1.1959 - val_accuracy: 0.4973 - val_loss: 1.1426\n",
            "Epoch 8/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.4981 - loss: 1.1144 - val_accuracy: 0.5459 - val_loss: 1.1180\n",
            "Epoch 9/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - accuracy: 0.4953 - loss: 1.0840 - val_accuracy: 0.5405 - val_loss: 1.0920\n",
            "Epoch 10/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - accuracy: 0.5460 - loss: 1.0193 - val_accuracy: 0.5730 - val_loss: 1.0562\n",
            "Epoch 11/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 170ms/step - accuracy: 0.5778 - loss: 0.9800 - val_accuracy: 0.5892 - val_loss: 1.0031\n",
            "Epoch 12/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - accuracy: 0.5793 - loss: 0.9497 - val_accuracy: 0.6378 - val_loss: 0.9553\n",
            "Epoch 13/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - accuracy: 0.6336 - loss: 0.8832 - val_accuracy: 0.6378 - val_loss: 0.9297\n",
            "Epoch 14/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 163ms/step - accuracy: 0.6511 - loss: 0.8286 - val_accuracy: 0.6324 - val_loss: 0.8807\n",
            "Epoch 15/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - accuracy: 0.6903 - loss: 0.7862 - val_accuracy: 0.6649 - val_loss: 0.8572\n",
            "Epoch 16/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 132ms/step - accuracy: 0.7583 - loss: 0.6761 - val_accuracy: 0.6757 - val_loss: 0.8329\n",
            "Epoch 17/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 166ms/step - accuracy: 0.7668 - loss: 0.6394 - val_accuracy: 0.6811 - val_loss: 0.7916\n",
            "Epoch 18/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 96ms/step - accuracy: 0.8045 - loss: 0.5692 - val_accuracy: 0.6811 - val_loss: 0.7899\n",
            "Epoch 19/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 128ms/step - accuracy: 0.8261 - loss: 0.5291 - val_accuracy: 0.6811 - val_loss: 0.7700\n",
            "Epoch 20/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - accuracy: 0.8162 - loss: 0.5212 - val_accuracy: 0.7027 - val_loss: 0.7943\n",
            "Epoch 21/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 137ms/step - accuracy: 0.8451 - loss: 0.4748 - val_accuracy: 0.6973 - val_loss: 0.7911\n",
            "Epoch 22/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - accuracy: 0.8664 - loss: 0.4237 - val_accuracy: 0.7027 - val_loss: 0.7714\n",
            "Epoch 23/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 160ms/step - accuracy: 0.8855 - loss: 0.3900 - val_accuracy: 0.6865 - val_loss: 0.7907\n",
            "Epoch 24/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 94ms/step - accuracy: 0.8930 - loss: 0.3721 - val_accuracy: 0.7027 - val_loss: 0.7838\n",
            "Epoch 25/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 148ms/step - accuracy: 0.9113 - loss: 0.3301 - val_accuracy: 0.7135 - val_loss: 0.7878\n",
            "Epoch 26/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 190ms/step - accuracy: 0.9210 - loss: 0.2961 - val_accuracy: 0.7243 - val_loss: 0.7703\n",
            "Epoch 27/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 96ms/step - accuracy: 0.9123 - loss: 0.3161 - val_accuracy: 0.7081 - val_loss: 0.7895\n",
            "Epoch 28/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 163ms/step - accuracy: 0.9200 - loss: 0.3082 - val_accuracy: 0.7081 - val_loss: 0.7880\n",
            "Epoch 29/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - accuracy: 0.9415 - loss: 0.2519 - val_accuracy: 0.7189 - val_loss: 0.7902\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Concatenate, Input, Embedding, LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "\n",
        "# --- TEXT INPUT BRANCH ---\n",
        "text_input = Input(shape=(MAX_LEN,), name=\"text_input\")\n",
        "x_text = Embedding(\n",
        "    input_dim=num_words,\n",
        "    output_dim=EMBEDDING_DIM,\n",
        "    weights=[embedding_matrix],\n",
        "    input_length=MAX_LEN,\n",
        "    trainable=True\n",
        ")(text_input)\n",
        "\n",
        "x_text = Bidirectional(LSTM(\n",
        "    64,\n",
        "    return_sequences=True,\n",
        "    dropout=0.4,\n",
        "    recurrent_dropout=0.4,\n",
        "))(x_text)\n",
        "x_text = AttentionLayer()(x_text)\n",
        "\n",
        "# --- NUMERIC INPUT BRANCH ---\n",
        "numeric_input = Input(shape=(NUM_NUMERIC_FEATURES,), name=\"numeric_input\")\n",
        "\n",
        "# Optional: normalization/dense layer\n",
        "x_numeric = BatchNormalization()(numeric_input)\n",
        "\n",
        "# --- CONCATENATE BOTH ---\n",
        "x = Concatenate()([x_text, x_numeric])\n",
        "\n",
        "# Fully connected layers\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# Output\n",
        "output = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Build model\n",
        "model_bilstm_2 = Model(inputs=[text_input, numeric_input], outputs=output)\n",
        "model_bilstm_2.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_bilstm_2.summary()\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "\n",
        "history_bilstm = model_bilstm_2.fit(\n",
        "    {\"text_input\": X_text_train, \"numeric_input\": X_num_train_2},\n",
        "    y_train,\n",
        "    validation_split=0.1,\n",
        "    shuffle=True,  # penting\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks = [early_stopping],\n",
        "    class_weight=class_weights_dict\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEJ9Z9CKnONJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a96f8fa-ec4e-4469-e876-27ba37bcddca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8214    0.7667    0.7931        30\n",
            "           1     0.8205    0.7619    0.7901        84\n",
            "           2     0.6078    0.7209    0.6596        43\n",
            "\n",
            "    accuracy                         0.7516       157\n",
            "   macro avg     0.7499    0.7498    0.7476       157\n",
            "weighted avg     0.7624    0.7516    0.7549       157\n",
            "\n",
            "Precision: 0.7499\n",
            "Recall:    0.7498\n",
            "F1-score:  0.7476\n",
            "Accuracy:  0.7516\n"
          ]
        }
      ],
      "source": [
        "evaluate_grouped(model_bilstm_2, X_text_test, X_num_test_2, group_keys_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzRePgy31hTG"
      },
      "outputs": [],
      "source": [
        "# model_bilstm_2.save(\"/content/drive/MyDrive/Thesis/Final Project/main/model_scenario_2/model_bilstm_2.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfoJvEBBlqTX"
      },
      "source": [
        "---\n",
        "### **GRU (2 FEATURES)**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dVDA19WmIIM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "917e3a37-f243-423c-dece-cfa438fab934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_19\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_19\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ text_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_19        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m1,089,000\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru_6 (\u001b[38;5;33mGRU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m70,272\u001b[0m │ embedding_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ numeric_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer_19  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m65\u001b[0m │ gru_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m4\u001b[0m │ numeric_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_19      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ attention_layer_… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_38          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ concatenate_19[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,224\u001b[0m │ dropout_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ dense_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_39          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m195\u001b[0m │ dropout_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ text_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_19        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,089,000</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">70,272</span> │ embedding_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ numeric_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer_19  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ gru_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)    │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │ numeric_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_19      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_layer_… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_38          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │ dropout_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_39          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ dropout_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,164,016\u001b[0m (4.44 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,164,016</span> (4.44 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,163,886\u001b[0m (4.44 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,163,886</span> (4.44 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m130\u001b[0m (520.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> (520.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 78ms/step - accuracy: 0.3172 - loss: 1.8412 - val_accuracy: 0.3405 - val_loss: 1.1688\n",
            "Epoch 2/35\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 105ms/step - accuracy: 0.3538 - loss: 1.3931 - val_accuracy: 0.3514 - val_loss: 1.1638\n",
            "Epoch 3/35\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.3858 - loss: 1.2608 - val_accuracy: 0.3730 - val_loss: 1.1502\n",
            "Epoch 4/35\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.3756 - loss: 1.2718 - val_accuracy: 0.4486 - val_loss: 1.1395\n",
            "Epoch 5/35\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.4014 - loss: 1.2406 - val_accuracy: 0.4270 - val_loss: 1.1265\n",
            "Epoch 6/35\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 103ms/step - accuracy: 0.4181 - loss: 1.2045 - val_accuracy: 0.4595 - val_loss: 1.1105\n",
            "Epoch 7/35\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - accuracy: 0.4516 - loss: 1.1498 - val_accuracy: 0.5189 - val_loss: 1.0892\n",
            "Epoch 8/35\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 72ms/step - accuracy: 0.5279 - loss: 1.0699 - val_accuracy: 0.5189 - val_loss: 1.0522\n",
            "Epoch 9/35\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - accuracy: 0.5345 - loss: 1.0268 - val_accuracy: 0.5892 - val_loss: 0.9892\n",
            "Epoch 10/35\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - accuracy: 0.6158 - loss: 0.9241 - val_accuracy: 0.6378 - val_loss: 0.9157\n",
            "Epoch 11/35\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.6716 - loss: 0.8157 - val_accuracy: 0.6595 - val_loss: 0.8441\n",
            "Epoch 12/35\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - accuracy: 0.7345 - loss: 0.6938 - val_accuracy: 0.6811 - val_loss: 0.7992\n",
            "Epoch 13/35\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.7866 - loss: 0.6124 - val_accuracy: 0.6919 - val_loss: 0.7579\n",
            "Epoch 14/35\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.8227 - loss: 0.5091 - val_accuracy: 0.6919 - val_loss: 0.7432\n",
            "Epoch 15/35\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.8751 - loss: 0.4074 - val_accuracy: 0.7135 - val_loss: 0.7334\n",
            "Epoch 16/35\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 102ms/step - accuracy: 0.9130 - loss: 0.3401 - val_accuracy: 0.7135 - val_loss: 0.7367\n",
            "Epoch 17/35\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - accuracy: 0.8936 - loss: 0.3561 - val_accuracy: 0.7189 - val_loss: 0.7484\n",
            "Epoch 18/35\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.9167 - loss: 0.3094 - val_accuracy: 0.7243 - val_loss: 0.7727\n",
            "Epoch 19/35\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - accuracy: 0.9297 - loss: 0.2605 - val_accuracy: 0.7243 - val_loss: 0.7750\n",
            "Epoch 20/35\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - accuracy: 0.9304 - loss: 0.2503 - val_accuracy: 0.7135 - val_loss: 0.7876\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Concatenate, Input, Embedding, LSTM, Dense, Dropout, BatchNormalization, GRU\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# --- TEXT INPUT BRANCH ---\n",
        "text_input = Input(shape=(MAX_LEN,), name=\"text_input\")\n",
        "x_text = Embedding(\n",
        "    input_dim=num_words,\n",
        "    output_dim=EMBEDDING_DIM,\n",
        "    weights=[embedding_matrix],\n",
        "    input_length=MAX_LEN,\n",
        "    trainable=True\n",
        ")(text_input)\n",
        "\n",
        "x_text = GRU(\n",
        "    64,\n",
        "    return_sequences=True,\n",
        "    dropout=0.4,\n",
        "    recurrent_dropout=0.4,\n",
        ")(x_text)\n",
        "x_text = AttentionLayer()(x_text)\n",
        "\n",
        "# --- NUMERIC INPUT BRANCH ---\n",
        "numeric_input = Input(shape=(NUM_NUMERIC_FEATURES,), name=\"numeric_input\")\n",
        "\n",
        "# Optional: normalization/dense layer\n",
        "x_numeric = BatchNormalization()(numeric_input)\n",
        "\n",
        "# --- CONCATENATE BOTH ---\n",
        "x = Concatenate()([x_text, x_numeric])\n",
        "\n",
        "# Fully connected layers\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# Output\n",
        "output = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Build model\n",
        "model_gru_2 = Model(inputs=[text_input, numeric_input], outputs=output)\n",
        "model_gru_2.compile(\n",
        "    optimizer=Adam(learning_rate=2e-4),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_gru_2.summary()\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "\n",
        "history_gru = model_gru_2.fit(\n",
        "    {\"text_input\": X_text_train, \"numeric_input\": X_num_train_2},\n",
        "    y_train,\n",
        "    validation_split=0.1,\n",
        "    shuffle=True,  # penting\n",
        "    epochs=35,\n",
        "    batch_size=32,\n",
        "    callbacks = [early_stopping],\n",
        "    class_weight=class_weights_dict\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAUsqMRynXxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79520497-be5a-4f8d-c784-33ba57901b7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8636    0.6333    0.7308        30\n",
            "           1     0.7667    0.8214    0.7931        84\n",
            "           2     0.6444    0.6744    0.6591        43\n",
            "\n",
            "    accuracy                         0.7452       157\n",
            "   macro avg     0.7582    0.7097    0.7277       157\n",
            "weighted avg     0.7517    0.7452    0.7445       157\n",
            "\n",
            "Precision: 0.7582\n",
            "Recall:    0.7097\n",
            "F1-score:  0.7277\n",
            "Accuracy:  0.7452\n"
          ]
        }
      ],
      "source": [
        "evaluate_grouped(model_gru_2, X_text_test, X_num_test_2, group_keys_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TqmrGJ5fs81"
      },
      "outputs": [],
      "source": [
        "# model_gru_2.save(\"/content/drive/MyDrive/Thesis/Final Project/main/model_scenario_2/model_gru_2.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kefkEPgFo-lq"
      },
      "source": [
        "---\n",
        "## **1 FEATURE**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxkUH1d_lrdV"
      },
      "source": [
        "---\n",
        "### **LSTM (1 FEATURES)**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyO0eV2lTzii",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2ee3ae98-ba4d-4ed0-a2df-b458f80d7470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_26\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_26\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_26 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │     \u001b[38;5;34m1,089,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_17 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m93,440\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ attention_layer_26              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │            \u001b[38;5;34m65\u001b[0m │\n",
              "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_52 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_46          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_52 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_53 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_53 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,089,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">93,440</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ attention_layer_26              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_46          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,187,116\u001b[0m (4.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,187,116</span> (4.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,186,988\u001b[0m (4.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,186,988</span> (4.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 73ms/step - accuracy: 0.3143 - loss: 1.2783 - val_accuracy: 0.3405 - val_loss: 1.1631\n",
            "Epoch 2/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - accuracy: 0.3579 - loss: 1.2288 - val_accuracy: 0.3784 - val_loss: 1.1613\n",
            "Epoch 3/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 96ms/step - accuracy: 0.4105 - loss: 1.1828 - val_accuracy: 0.3838 - val_loss: 1.1589\n",
            "Epoch 4/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.3874 - loss: 1.1942 - val_accuracy: 0.3892 - val_loss: 1.1560\n",
            "Epoch 5/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.4211 - loss: 1.1584 - val_accuracy: 0.4000 - val_loss: 1.1524\n",
            "Epoch 6/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.4734 - loss: 1.1251 - val_accuracy: 0.4973 - val_loss: 1.1465\n",
            "Epoch 7/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 92ms/step - accuracy: 0.4541 - loss: 1.1260 - val_accuracy: 0.4703 - val_loss: 1.1360\n",
            "Epoch 8/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.4607 - loss: 1.1228 - val_accuracy: 0.5297 - val_loss: 1.1215\n",
            "Epoch 9/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - accuracy: 0.5314 - loss: 1.0442 - val_accuracy: 0.5892 - val_loss: 1.1061\n",
            "Epoch 10/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.5369 - loss: 1.0342 - val_accuracy: 0.5946 - val_loss: 1.0770\n",
            "Epoch 11/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.5827 - loss: 0.9811 - val_accuracy: 0.6000 - val_loss: 1.0400\n",
            "Epoch 12/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - accuracy: 0.6177 - loss: 0.9387 - val_accuracy: 0.6054 - val_loss: 0.9951\n",
            "Epoch 13/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.6752 - loss: 0.8653 - val_accuracy: 0.6162 - val_loss: 0.9502\n",
            "Epoch 14/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 58ms/step - accuracy: 0.6833 - loss: 0.8277 - val_accuracy: 0.6541 - val_loss: 0.8954\n",
            "Epoch 15/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.7273 - loss: 0.7529 - val_accuracy: 0.6811 - val_loss: 0.8462\n",
            "Epoch 16/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.7528 - loss: 0.7095 - val_accuracy: 0.6811 - val_loss: 0.8179\n",
            "Epoch 17/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.7625 - loss: 0.6839 - val_accuracy: 0.6865 - val_loss: 0.7992\n",
            "Epoch 18/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.7859 - loss: 0.6174 - val_accuracy: 0.6865 - val_loss: 0.7843\n",
            "Epoch 19/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8115 - loss: 0.5701 - val_accuracy: 0.6757 - val_loss: 0.7711\n",
            "Epoch 20/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.8431 - loss: 0.5160 - val_accuracy: 0.6811 - val_loss: 0.7577\n",
            "Epoch 21/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.8387 - loss: 0.4869 - val_accuracy: 0.6703 - val_loss: 0.7618\n",
            "Epoch 22/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.8751 - loss: 0.4272 - val_accuracy: 0.7081 - val_loss: 0.7346\n",
            "Epoch 23/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 64ms/step - accuracy: 0.8640 - loss: 0.4361 - val_accuracy: 0.6865 - val_loss: 0.7641\n",
            "Epoch 24/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.8897 - loss: 0.3928 - val_accuracy: 0.7081 - val_loss: 0.7652\n",
            "Epoch 25/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - accuracy: 0.8877 - loss: 0.3632 - val_accuracy: 0.6973 - val_loss: 0.7510\n",
            "Epoch 26/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.8985 - loss: 0.3498 - val_accuracy: 0.6919 - val_loss: 0.7619\n",
            "Epoch 27/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - accuracy: 0.8921 - loss: 0.3502 - val_accuracy: 0.7027 - val_loss: 0.7631\n",
            "Epoch 28/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - accuracy: 0.9183 - loss: 0.3073 - val_accuracy: 0.7027 - val_loss: 0.7822\n",
            "Epoch 29/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.9068 - loss: 0.3418 - val_accuracy: 0.7081 - val_loss: 0.7897\n",
            "Epoch 30/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.9166 - loss: 0.3136 - val_accuracy: 0.7027 - val_loss: 0.7865\n",
            "Epoch 31/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - accuracy: 0.9250 - loss: 0.2718 - val_accuracy: 0.7081 - val_loss: 0.8002\n",
            "Epoch 32/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.9272 - loss: 0.2770 - val_accuracy: 0.7081 - val_loss: 0.8028\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dropout, Dense\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "input_ = Input(shape=(MAX_LEN,))\n",
        "x = Embedding(\n",
        "    input_dim=num_words,\n",
        "    output_dim=EMBEDDING_DIM,\n",
        "    weights=[embedding_matrix],\n",
        "    input_length=MAX_LEN,\n",
        "    trainable=True\n",
        ")(input_)\n",
        "\n",
        "x = LSTM(64,\n",
        "         return_sequences=True,\n",
        "         dropout=0.4,\n",
        "         recurrent_dropout=0.4)(x)\n",
        "x = AttentionLayer()(x)\n",
        "\n",
        "x = Dropout(0.4)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "output = Dense(3, activation='softmax')(x)\n",
        "\n",
        "model_lstm_1 = Model(inputs=input_, outputs=output)\n",
        "model_lstm_1.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model_lstm_1.summary()\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "\n",
        "history_lstm_1 = model_lstm_1.fit(\n",
        "    X_text_train,\n",
        "    y_train,\n",
        "    validation_split=0.1,\n",
        "    shuffle=True,  # penting\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks = [early_stopping],\n",
        "    class_weight=class_weights_dict\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAoEn9gxUC2B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a75e51bb-1801-42c8-9732-db6d7b882a85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7778    0.7000    0.7368        30\n",
            "           1     0.8171    0.7976    0.8072        84\n",
            "           2     0.6250    0.6977    0.6593        43\n",
            "\n",
            "    accuracy                         0.7516       157\n",
            "   macro avg     0.7400    0.7318    0.7345       157\n",
            "weighted avg     0.7570    0.7516    0.7533       157\n",
            "\n",
            "Precision: 0.7400\n",
            "Recall:    0.7318\n",
            "F1-score:  0.7345\n",
            "Accuracy:  0.7516\n"
          ]
        }
      ],
      "source": [
        "evaluate_single(model_lstm_1, X_text_test, group_keys_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkLoewSTfxMw"
      },
      "outputs": [],
      "source": [
        "# model_lstm_1.save(\"/content/drive/MyDrive/Thesis/Final Project/main/model_scenario_2/model_lstm_1.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_8nt979ls27"
      },
      "source": [
        "---\n",
        "### **BILSTM (1 FEATURES)**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHKSWr6wNrV7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7960bab6-22ee-4b92-f14e-225cb894a846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_27\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_27\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_27 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │     \u001b[38;5;34m1,089,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_8 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m186,880\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ attention_layer_27              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m129\u001b[0m │\n",
              "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_54 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_47          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_54 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_55 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_55 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,089,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">186,880</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ attention_layer_27              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_47          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,284,972\u001b[0m (4.90 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,284,972</span> (4.90 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,284,716\u001b[0m (4.90 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,284,716</span> (4.90 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 179ms/step - accuracy: 0.3358 - loss: 1.2970 - val_accuracy: 0.3946 - val_loss: 1.1818\n",
            "Epoch 2/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 163ms/step - accuracy: 0.3645 - loss: 1.2588 - val_accuracy: 0.3622 - val_loss: 1.1813\n",
            "Epoch 3/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 93ms/step - accuracy: 0.3874 - loss: 1.2062 - val_accuracy: 0.3784 - val_loss: 1.1797\n",
            "Epoch 4/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - accuracy: 0.4306 - loss: 1.2052 - val_accuracy: 0.3838 - val_loss: 1.1774\n",
            "Epoch 5/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.4614 - loss: 1.1627 - val_accuracy: 0.4108 - val_loss: 1.1733\n",
            "Epoch 6/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.4615 - loss: 1.1247 - val_accuracy: 0.4649 - val_loss: 1.1653\n",
            "Epoch 7/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 96ms/step - accuracy: 0.4775 - loss: 1.1136 - val_accuracy: 0.5027 - val_loss: 1.1557\n",
            "Epoch 8/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 169ms/step - accuracy: 0.5173 - loss: 1.0599 - val_accuracy: 0.5459 - val_loss: 1.1408\n",
            "Epoch 9/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.5261 - loss: 1.0647 - val_accuracy: 0.5784 - val_loss: 1.1201\n",
            "Epoch 10/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.5917 - loss: 0.9899 - val_accuracy: 0.6162 - val_loss: 1.0878\n",
            "Epoch 11/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 168ms/step - accuracy: 0.6172 - loss: 0.9631 - val_accuracy: 0.6378 - val_loss: 1.0447\n",
            "Epoch 12/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.6291 - loss: 0.9215 - val_accuracy: 0.6378 - val_loss: 1.0090\n",
            "Epoch 13/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 176ms/step - accuracy: 0.7046 - loss: 0.8402 - val_accuracy: 0.6811 - val_loss: 0.9559\n",
            "Epoch 14/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 210ms/step - accuracy: 0.7093 - loss: 0.8173 - val_accuracy: 0.6757 - val_loss: 0.9073\n",
            "Epoch 15/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 142ms/step - accuracy: 0.7319 - loss: 0.7585 - val_accuracy: 0.7027 - val_loss: 0.8442\n",
            "Epoch 16/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.7759 - loss: 0.6951 - val_accuracy: 0.7189 - val_loss: 0.8060\n",
            "Epoch 17/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - accuracy: 0.8165 - loss: 0.6216 - val_accuracy: 0.7189 - val_loss: 0.7743\n",
            "Epoch 18/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - accuracy: 0.8501 - loss: 0.5467 - val_accuracy: 0.6865 - val_loss: 0.7833\n",
            "Epoch 19/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.8549 - loss: 0.5126 - val_accuracy: 0.7027 - val_loss: 0.7337\n",
            "Epoch 20/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 169ms/step - accuracy: 0.8504 - loss: 0.5085 - val_accuracy: 0.7297 - val_loss: 0.7180\n",
            "Epoch 21/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 95ms/step - accuracy: 0.8651 - loss: 0.4438 - val_accuracy: 0.7135 - val_loss: 0.7258\n",
            "Epoch 22/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 117ms/step - accuracy: 0.8907 - loss: 0.4009 - val_accuracy: 0.6919 - val_loss: 0.7730\n",
            "Epoch 23/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.8783 - loss: 0.3947 - val_accuracy: 0.6973 - val_loss: 0.7460\n",
            "Epoch 24/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.8919 - loss: 0.3726 - val_accuracy: 0.7243 - val_loss: 0.7241\n",
            "Epoch 25/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 166ms/step - accuracy: 0.9182 - loss: 0.3285 - val_accuracy: 0.7351 - val_loss: 0.7177\n",
            "Epoch 26/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 94ms/step - accuracy: 0.9278 - loss: 0.2983 - val_accuracy: 0.7405 - val_loss: 0.7220\n",
            "Epoch 27/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 123ms/step - accuracy: 0.9278 - loss: 0.2813 - val_accuracy: 0.7514 - val_loss: 0.7486\n",
            "Epoch 28/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.9347 - loss: 0.2520 - val_accuracy: 0.7135 - val_loss: 0.7882\n",
            "Epoch 29/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.9373 - loss: 0.2581 - val_accuracy: 0.7297 - val_loss: 0.7712\n",
            "Epoch 30/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 95ms/step - accuracy: 0.9418 - loss: 0.2329 - val_accuracy: 0.7514 - val_loss: 0.7458\n",
            "Epoch 31/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.9463 - loss: 0.2483 - val_accuracy: 0.7459 - val_loss: 0.7538\n",
            "Epoch 32/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 204ms/step - accuracy: 0.9439 - loss: 0.2317 - val_accuracy: 0.7297 - val_loss: 0.7861\n",
            "Epoch 33/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 142ms/step - accuracy: 0.9540 - loss: 0.2068 - val_accuracy: 0.7297 - val_loss: 0.7998\n",
            "Epoch 34/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.9617 - loss: 0.2005 - val_accuracy: 0.7351 - val_loss: 0.8183\n",
            "Epoch 35/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 128ms/step - accuracy: 0.9644 - loss: 0.1935 - val_accuracy: 0.7405 - val_loss: 0.8096\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dropout, Dense\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "input_ = Input(shape=(MAX_LEN,))\n",
        "x = Embedding(\n",
        "    input_dim=num_words,\n",
        "    output_dim=EMBEDDING_DIM,\n",
        "    weights=[embedding_matrix],\n",
        "    input_length=MAX_LEN,\n",
        "    trainable=True\n",
        ")(input_)\n",
        "x = Bidirectional(LSTM(64, return_sequences=True, dropout=0.4, recurrent_dropout=0.4))(x)\n",
        "x = AttentionLayer()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "x = Dropout(0.2)(x)\n",
        "output = Dense(3, activation='softmax')(x)\n",
        "\n",
        "model_bilstm_1 = Model(inputs=input_, outputs=output)\n",
        "model_bilstm_1.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model_bilstm_1.summary()\n",
        "\n",
        "\n",
        "history_bilstm_1 = model_bilstm_1.fit(\n",
        "    X_text_train,\n",
        "    y_train,\n",
        "    validation_split=0.1,\n",
        "    shuffle=True,  # penting\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks = [early_stopping],\n",
        "    class_weight=class_weights_dict\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlfhJQNrR16R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47630518-3dc2-4a2a-99c5-315725fc04c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7917    0.6333    0.7037        30\n",
            "           1     0.7791    0.7976    0.7882        84\n",
            "           2     0.6170    0.6744    0.6444        43\n",
            "\n",
            "    accuracy                         0.7325       157\n",
            "   macro avg     0.7293    0.7018    0.7121       157\n",
            "weighted avg     0.7371    0.7325    0.7327       157\n",
            "\n",
            "Precision: 0.7293\n",
            "Recall:    0.7018\n",
            "F1-score:  0.7121\n",
            "Accuracy:  0.7325\n"
          ]
        }
      ],
      "source": [
        "evaluate_single(model_bilstm_1, X_text_test, group_keys_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKcPs9R71mYi"
      },
      "outputs": [],
      "source": [
        "# model_bilstm_1.save(\"/content/drive/MyDrive/Thesis/Final Project/main/model_scenario_2/model_bilstm_1.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tZMy4HOluWx"
      },
      "source": [
        "---\n",
        "### **GRU (1 FEATURES)**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuRquTlvlnrr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "da2b27ee-d394-451d-d6fa-342e5e2ee893"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_25\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_25\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_25 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │     \u001b[38;5;34m1,089,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_8 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m70,272\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ attention_layer_25              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │            \u001b[38;5;34m65\u001b[0m │\n",
              "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_50 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_45          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_50 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_51 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_51 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,089,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">70,272</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ attention_layer_25              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_45          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,163,948\u001b[0m (4.44 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,163,948</span> (4.44 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,163,820\u001b[0m (4.44 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,163,820</span> (4.44 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 148ms/step - accuracy: 0.3600 - loss: 1.2927 - val_accuracy: 0.4649 - val_loss: 1.1579\n",
            "Epoch 2/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - accuracy: 0.4066 - loss: 1.1889 - val_accuracy: 0.3730 - val_loss: 1.1558\n",
            "Epoch 3/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.3817 - loss: 1.1919 - val_accuracy: 0.4432 - val_loss: 1.1518\n",
            "Epoch 4/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 105ms/step - accuracy: 0.4677 - loss: 1.1366 - val_accuracy: 0.4541 - val_loss: 1.1482\n",
            "Epoch 5/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - accuracy: 0.4926 - loss: 1.1087 - val_accuracy: 0.5730 - val_loss: 1.1389\n",
            "Epoch 6/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 0.5139 - loss: 1.0595 - val_accuracy: 0.5622 - val_loss: 1.1235\n",
            "Epoch 7/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 98ms/step - accuracy: 0.5580 - loss: 1.0014 - val_accuracy: 0.6270 - val_loss: 1.0943\n",
            "Epoch 8/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - accuracy: 0.6170 - loss: 0.9138 - val_accuracy: 0.6595 - val_loss: 1.0479\n",
            "Epoch 9/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.6705 - loss: 0.8759 - val_accuracy: 0.6973 - val_loss: 0.9866\n",
            "Epoch 10/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - accuracy: 0.7174 - loss: 0.7754 - val_accuracy: 0.7135 - val_loss: 0.9057\n",
            "Epoch 11/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.7762 - loss: 0.6857 - val_accuracy: 0.7081 - val_loss: 0.8228\n",
            "Epoch 12/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.7791 - loss: 0.6307 - val_accuracy: 0.7189 - val_loss: 0.7645\n",
            "Epoch 13/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8196 - loss: 0.5235 - val_accuracy: 0.7027 - val_loss: 0.7464\n",
            "Epoch 14/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 96ms/step - accuracy: 0.8545 - loss: 0.4830 - val_accuracy: 0.7351 - val_loss: 0.7014\n",
            "Epoch 15/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 129ms/step - accuracy: 0.8824 - loss: 0.4086 - val_accuracy: 0.7243 - val_loss: 0.6933\n",
            "Epoch 16/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 69ms/step - accuracy: 0.9052 - loss: 0.3501 - val_accuracy: 0.7189 - val_loss: 0.7009\n",
            "Epoch 17/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.8975 - loss: 0.3431 - val_accuracy: 0.6973 - val_loss: 0.7756\n",
            "Epoch 18/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.9191 - loss: 0.2930 - val_accuracy: 0.6973 - val_loss: 0.7787\n",
            "Epoch 19/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - accuracy: 0.9350 - loss: 0.2613 - val_accuracy: 0.7459 - val_loss: 0.7619\n",
            "Epoch 20/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - accuracy: 0.9313 - loss: 0.2454 - val_accuracy: 0.7189 - val_loss: 0.8046\n",
            "Epoch 21/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 102ms/step - accuracy: 0.9441 - loss: 0.2364 - val_accuracy: 0.7297 - val_loss: 0.7967\n",
            "Epoch 22/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - accuracy: 0.9502 - loss: 0.2247 - val_accuracy: 0.7405 - val_loss: 0.7837\n",
            "Epoch 23/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 149ms/step - accuracy: 0.9485 - loss: 0.2057 - val_accuracy: 0.7351 - val_loss: 0.8001\n",
            "Epoch 24/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.9480 - loss: 0.2085 - val_accuracy: 0.7405 - val_loss: 0.8166\n",
            "Epoch 25/100\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.9595 - loss: 0.1773 - val_accuracy: 0.7405 - val_loss: 0.8326\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dropout, Dense\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "input_ = Input(shape=(MAX_LEN,))\n",
        "x = Embedding(\n",
        "    input_dim=num_words,\n",
        "    output_dim=EMBEDDING_DIM,\n",
        "    weights=[embedding_matrix],\n",
        "    input_length=MAX_LEN,\n",
        "    trainable=True\n",
        ")(input_)\n",
        "x = GRU(64, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)(x)\n",
        "x = AttentionLayer()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(3, activation='softmax')(x)\n",
        "\n",
        "model_gru_1 = Model(inputs=input_, outputs=output)\n",
        "model_gru_1.compile(optimizer=Adam(learning_rate=2e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model_gru_1.summary()\n",
        "\n",
        "\n",
        "history_gru_1 = model_gru_1.fit(\n",
        "    X_text_train,\n",
        "    y_train,\n",
        "    validation_split=0.1,\n",
        "    shuffle=True,  # penting\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks = [early_stopping],\n",
        "    class_weight=class_weights_dict\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IIEHZVGXEEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47da0b55-7141-4851-dad7-9ee9fb235c7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7857    0.7333    0.7586        30\n",
            "           1     0.7907    0.8095    0.8000        84\n",
            "           2     0.6512    0.6512    0.6512        43\n",
            "\n",
            "    accuracy                         0.7516       157\n",
            "   macro avg     0.7425    0.7313    0.7366       157\n",
            "weighted avg     0.7515    0.7516    0.7513       157\n",
            "\n",
            "Precision: 0.7425\n",
            "Recall:    0.7313\n",
            "F1-score:  0.7366\n",
            "Accuracy:  0.7516\n"
          ]
        }
      ],
      "source": [
        "evaluate_single(model_gru_1, X_text_test, group_keys_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0_00g60f1c9"
      },
      "outputs": [],
      "source": [
        "# model_gru_1.save(\"/content/drive/MyDrive/Thesis/Final Project/main/model_scenario_2/model_gru_1.h5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}